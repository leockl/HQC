{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "from sklearn.preprocessing import normalize\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "class hqc(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"The Helstrom Quantum Centroid (HQC) classifier is a quantum-inspired supervised \n",
    "    classification approach for data with binary classes (ie. data with 2 classes only).\n",
    "                         \n",
    "    Parameters\n",
    "    ----------\n",
    "    rescale : int or float, default = 1\n",
    "        The dataset rescaling factor. A parameter used for rescaling the dataset. \n",
    "    n_copies : int, default = 1\n",
    "        The number of copies to take for each quantum density. This is equivalent to taking \n",
    "        the n-fold Kronecker tensor product for each quantum density.\n",
    "    encoding : str, default = 'amplit'\n",
    "        The encoding method used to encode vectors into quantum densities. Possible values:\n",
    "        'amplit', 'stereo'. 'amplit' means using the amplitude encoding method. 'stereo' means \n",
    "        using the inverse of the standard stereographic projection encoding method. Default set \n",
    "        to 'amplit'.\n",
    "    class_wgt : str, default = 'equi'\n",
    "        The class weights assigned to the Quantum Helstrom observable terms. Possible values: \n",
    "        'equi', 'weighted'. 'equi' means assigning equal weights of 1/2 (equiprobable) to the\n",
    "        two classes in the Quantum Helstrom observable. 'weighted' means assigning weights equal \n",
    "        to the proportion of the number of rows in each class to the two classes in the Quantum \n",
    "        Helstrom observable. Default set to 'equi'.\n",
    "    n_jobs : int, default = None\n",
    "        The number of CPU cores used when parallelizing. If -1 all CPUs are used. If 1 is given, \n",
    "        no parallel computing code is used at all. For n_jobs below -1, (n_cpus + 1 + n_jobs) \n",
    "        are used. Thus for n_jobs = -2, all CPUs but one are used. None is a marker for ‘unset’ \n",
    "        that will be interpreted as n_jobs = 1.\n",
    "    n_splits : int, default = 1\n",
    "        The number of subset splits performed on the input dataset row-wise and on the number \n",
    "        of eigenvalues/eigenvectors of the Quantum Helstrom observable for optimal speed \n",
    "        performance. If 1 is given, no splits are used. For optimal speed, recommend using \n",
    "        n_splits = int(numpy.ceil(number of CPU cores used/2)). If memory blow-out occurs, \n",
    "        reduce n_splits.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : ndarray, shape (2,)\n",
    "        Sorted binary classes.\n",
    "    centroid_ : ndarray, shape (2, n_features + 1, n_features + 1)\n",
    "        Quantum Centroids for class with index 0 and 1 respectively.\n",
    "    q_hels_obs_ : ndarray, shape (n_features + 1, n_features + 1)\n",
    "        Quantum Helstrom observable.\n",
    "    proj_sum_ : tuple, shape (2, n_features + 1, n_features + 1)\n",
    "        Sum of the projectors of the Quantum Helstrom observable's eigenvectors, which has\n",
    "        corresponding positive and negative eigenvalues respectively.\n",
    "    hels_bound_ : float\n",
    "        Helstrom bound is the upper bound of the probability that one can correctly \n",
    "        discriminate whether a quantum density is of which of the two binary quantum density \n",
    "        pattern.          \n",
    "    \"\"\"\n",
    "    # Added binary_only tag as required by sklearn check_estimator\n",
    "    def _more_tags(self):\n",
    "        return {'binary_only': True}\n",
    "    \n",
    "    \n",
    "    # Initialize model hyperparameters\n",
    "    def __init__(self, \n",
    "                 rescale = 1, \n",
    "                 n_copies = 1, \n",
    "                 encoding = 'amplit', \n",
    "                 class_wgt = 'equi', \n",
    "                 n_jobs = None, \n",
    "                 n_splits = 1):\n",
    "        self.rescale = rescale\n",
    "        self.n_copies = n_copies\n",
    "        self.encoding = encoding\n",
    "        self.class_wgt = class_wgt\n",
    "        self.n_jobs = n_jobs\n",
    "        self.n_splits = n_splits\n",
    "        \n",
    "    \n",
    "    # Function for fit\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Perform HQC classification with the inverse of the standard stereographic \n",
    "        projection encoding, with the option to rescale the dataset prior to encoding.\n",
    "                \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The training input samples. An array of int or float.\n",
    "        y : array-like, shape (n_samples,)\n",
    "            The training input binary target values. An array of str, int or float.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        # Ensure target y is of non-regression type  \n",
    "        # Added as required by sklearn check_estimator\n",
    "        check_classification_targets(y)\n",
    "    \n",
    "        # Store binary classes and encode y into binary class indexes 0 and 1\n",
    "        self.classes_, y_class_index = np.unique(y, return_inverse = True)\n",
    "        \n",
    "        # Cast X to float to ensure all following calculations below are done in float  \n",
    "        # rather than integer\n",
    "        X = X.astype(float)\n",
    "        \n",
    "        # Rescale X\n",
    "        X = self.rescale*X\n",
    "        \n",
    "        # Calculate sum of squares of each row (sample) in X\n",
    "        X_sq_sum = (X**2).sum(axis = 1)\n",
    "        \n",
    "        # Number of rows in X\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Number of columns in X\n",
    "        n = X.shape[1]\n",
    "        \n",
    "        # Calculate X' using amplitude or inverse of the standard stereographic projection \n",
    "        # encoding method\n",
    "        if self.encoding not in ['amplit', 'stereo']:\n",
    "            raise ValueError('encoding should be \"amplit\" or \"stereo\"')\n",
    "        elif self.encoding == 'amplit':\n",
    "            X_prime = normalize(np.concatenate((X, np.ones(m).reshape(-1, 1)), axis = 1))\n",
    "        else:\n",
    "            X_prime = (1 / (X_sq_sum + 1)).reshape(-1, 1) \\\n",
    "                      *(np.concatenate((2*X, (X_sq_sum - 1).reshape(-1, 1)), axis = 1))\n",
    "            \n",
    "        # Function to calculate terms in the Quantum Centroids and quantum Helstrom \n",
    "        # observable for each class\n",
    "        def centroid_terms_func(i):\n",
    "            # Determine rows (samples) in X' belonging to either class\n",
    "            X_prime_class = X_prime[y_class_index == i]\n",
    "            \n",
    "            # Number of rows (samples) in X' belonging to either class\n",
    "            m_class = X_prime_class.shape[0]\n",
    "            \n",
    "            # Split X' belonging to either class into n_splits subsets, row-wise\n",
    "            X_prime_class_split = np.array_split(X_prime_class, \n",
    "                                                 indices_or_sections = self.n_splits, \n",
    "                                                 axis = 0)\n",
    "            \n",
    "            # Function to calculate terms in the Quantum Centroids and quantum Helstrom\n",
    "            # observable for each class, per subset split\n",
    "            def X_prime_class_split_func(j):\n",
    "                # Counter for j-th split of X'\n",
    "                X_prime_class_split_jth = X_prime_class_split[j]\n",
    "                \n",
    "                # Number of rows (samples) in j-th split of X'\n",
    "                m_class_split = X_prime_class_split_jth.shape[0]\n",
    "            \n",
    "                # Number of rows/columns in density matrix\n",
    "                density_nrow_ncol = (n + 1)**self.n_copies\n",
    "            \n",
    "                # Initialize arrays density_sum, centroid and q_hels_obs_terms\n",
    "                density_sum = np.zeros((density_nrow_ncol, density_nrow_ncol))\n",
    "                centroid = density_sum\n",
    "                q_hels_obs_terms = density_sum\n",
    "                for k in range(m_class_split):\n",
    "                    # Encode vectors into quantum densities\n",
    "                    X_prime_class_split_each_row = X_prime_class_split_jth[k, :]\n",
    "                    density_each_row = np.dot(X_prime_class_split_each_row.reshape(-1, 1),\n",
    "                                              X_prime_class_split_each_row.reshape(1, -1))\n",
    "                \n",
    "                    # Calculate n-fold Kronecker tensor product\n",
    "                    if self.n_copies == 1:\n",
    "                        density_each_row = density_each_row\n",
    "                    else:\n",
    "                        density_each_row_copy = density_each_row\n",
    "                        for u in range(self.n_copies - 1):\n",
    "                            density_each_row = np.kron(density_each_row, density_each_row_copy)\n",
    "                \n",
    "                    # Calculate sum of quantum densities\n",
    "                    density_sum = density_sum + density_each_row\n",
    "                \n",
    "                    # Calculate Quantum Centroid\n",
    "                    # Added ZeroDivisionError as required by sklearn check_estimator\n",
    "                    try:\n",
    "                        centroid = (1 / m_class)*density_sum\n",
    "                    except ZeroDivisionError:\n",
    "                        centroid = 0\n",
    "                    \n",
    "                    # Calculate terms in the quantum Helstrom observable\n",
    "                    if self.class_wgt not in ['equi', 'weighted']:\n",
    "                        raise ValueError('class_wgt should be \"equi\" or \"weighted\"')\n",
    "                    elif self.class_wgt == 'equi':\n",
    "                        q_hels_obs_terms = 0.5*centroid\n",
    "                    else:\n",
    "                        q_hels_obs_terms = (1 / m)*density_sum                      \n",
    "                return m_class_split, centroid, q_hels_obs_terms        \n",
    "            return np.sum(Parallel(n_jobs = self.n_jobs) \\\n",
    "                         (delayed(X_prime_class_split_func)(j) for j in range(self.n_splits)), axis = 0)\n",
    "            \n",
    "        # Calculate Quantum Centroids and terms in the quantum Helstrom observable for each class\n",
    "        centroid_terms = np.array(Parallel(n_jobs = self.n_jobs) \\\n",
    "                                          (delayed(centroid_terms_func)(i) for i in range(2)))\n",
    "        \n",
    "        # Determine Quantum Centroids\n",
    "        self.centroid_ = centroid_terms[:, 1]\n",
    "           \n",
    "        # Calculate quantum Helstrom observable\n",
    "        self.q_hels_obs_ = centroid_terms[0, 2] - centroid_terms[1, 2]     \n",
    "        \n",
    "        # Calculate eigenvalues w and eigenvectors v of the quantum Helstrom observable\n",
    "        w, v = np.linalg.eigh(self.q_hels_obs_)\n",
    "        \n",
    "        # Length of w\n",
    "        len_w = len(w)\n",
    "        \n",
    "        # Initialize array eigval_class\n",
    "        eigval_class = np.empty_like(w)\n",
    "        for i in range(len_w):\n",
    "            # Create an array of 0s and 1s to indicate positive and negative eigenvalues\n",
    "            # respectively\n",
    "            if w[i] > 0:\n",
    "                eigval_class[i] = 0\n",
    "            else:\n",
    "                eigval_class[i] = 1\n",
    "        \n",
    "        # Transpose matrix v containing eigenvectors to row-wise\n",
    "        eigvec = v.T\n",
    "        \n",
    "        # Function to calculate sum of the projectors corresponding to positive and negative\n",
    "        # eigenvalues respectively\n",
    "        def sum_proj_func(i):\n",
    "            # Determine eigenvectors belonging to positive and negative eigenvalues respectively\n",
    "            eigvec_class = eigvec[eigval_class == i]\n",
    "            \n",
    "            # Split eigenvectors into n_splits subsets\n",
    "            eigvec_class_split = np.array_split(eigvec_class, \n",
    "                                                indices_or_sections = self.n_splits, \n",
    "                                                axis = 0)\n",
    "            \n",
    "            # Function to calculate sum of the projectors corresponding to positive and negative\n",
    "            # eigenvalues respectively, per subset split\n",
    "            def eigvec_class_split_func(j):\n",
    "                # Initialize array proj_sum_split\n",
    "                proj_sum_split = np.zeros_like(self.q_hels_obs_)\n",
    "                for k in eigvec_class_split[j]:\n",
    "                    # Calculate sum of the projectors corresponding to positive and negative\n",
    "                    # eigenvalues respectively, per subset split\n",
    "                    proj_sum_split = proj_sum_split + np.dot(k.reshape(-1, 1), k.reshape(1, -1))\n",
    "                return proj_sum_split        \n",
    "            return np.sum(Parallel(n_jobs = self.n_jobs) \\\n",
    "                         (delayed(eigvec_class_split_func)(j) for j in range(self.n_splits)), axis = 0)\n",
    "        \n",
    "        # Calculate sum of the projectors corresponding to positive and negative eigenvalues\n",
    "        # respectively\n",
    "        self.proj_sum_ = Parallel(n_jobs = self.n_jobs) \\\n",
    "                         (delayed(sum_proj_func)(i) for i in range(2))    \n",
    "                       \n",
    "        # Calculate Helstrom bound\n",
    "        self.hels_bound_ = (centroid_terms[0, 0] / m)*np.einsum('ij,ji->', self.centroid_[0], \n",
    "                                                                self.proj_sum_[0]) \\\n",
    "                           + (centroid_terms[1, 0] / m)*np.einsum('ij,ji->', self.centroid_[1], \n",
    "                                                                  self.proj_sum_[1])\n",
    "        return self\n",
    "        \n",
    "    \n",
    "    # Function for predict_proba\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Performs HQC classification on X and returns the trace of the dot product of the densities \n",
    "        and the sum of the projectors with corresponding positive and negative eigenvalues respectively.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The input samples. An array of int or float.       \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        trace_matrix : array-like, shape (n_samples, 2)\n",
    "            Column index 0 corresponds to the trace of the dot product of the densities and the sum  \n",
    "            of projectors with positive eigenvalues. Column index 1 corresponds to the trace of the  \n",
    "            dot product of the densities and the sum of projectors with negative eigenvalues. An array \n",
    "            of float.\n",
    "        \"\"\"\n",
    "        # Check if fit had been called\n",
    "        check_is_fitted(self, ['proj_sum_'])\n",
    "\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "        \n",
    "        # Cast X to float to ensure all following calculations below are done in float \n",
    "        # rather than integer\n",
    "        X = X.astype(float)        \n",
    "        \n",
    "        # Rescale X\n",
    "        X = self.rescale*X        \n",
    "        \n",
    "        # Calculate sum of squares of each row (sample) in X\n",
    "        X_sq_sum = (X**2).sum(axis = 1)\n",
    "        \n",
    "        # Number of rows in X\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Number of columns in X\n",
    "        n = X.shape[1]\n",
    "\n",
    "        # Calculate X' using amplitude or inverse of the standard stereographic projection \n",
    "        # encoding method\n",
    "        if self.encoding not in ['amplit', 'stereo']:\n",
    "            raise ValueError('encoding should be \"amplit\" or \"stereo\"')\n",
    "        elif self.encoding == 'amplit':\n",
    "            X_prime = normalize(np.concatenate((X, np.ones(m).reshape(-1, 1)), axis = 1))\n",
    "        else:\n",
    "            X_prime = (1 / (X_sq_sum + 1)).reshape(-1, 1) \\\n",
    "                      *(np.concatenate((2*X, (X_sq_sum - 1).reshape(-1, 1)), axis = 1))\n",
    "               \n",
    "        # Function to calculate trace values for each class\n",
    "        def trace_func(i):\n",
    "            # Split X' into n_splits subsets, row-wise\n",
    "            X_prime_split = np.array_split(X_prime, \n",
    "                                           indices_or_sections = self.n_splits, \n",
    "                                           axis = 0)\n",
    "            \n",
    "            # Function to calculate trace values for each class, per subset split\n",
    "            def trace_split_func(j):\n",
    "                # Counter for j-th split X'\n",
    "                X_prime_split_jth = X_prime_split[j]\n",
    "                \n",
    "                # Number of rows (samples) in j-th split X'\n",
    "                X_prime_split_m = X_prime_split_jth.shape[0]\n",
    "                \n",
    "                # Initialize array trace_class_split\n",
    "                trace_class_split = np.empty(X_prime_split_m)\n",
    "                for k in range(X_prime_split_m):\n",
    "                    # Encode vectors into quantum densities\n",
    "                    X_prime_split_each_row = X_prime_split_jth[k, :]\n",
    "                    density_each_row = np.dot(X_prime_split_each_row.reshape(-1, 1), \n",
    "                                              X_prime_split_each_row.reshape(1, -1))\n",
    "                \n",
    "                    # Calculate n-fold Kronecker tensor product\n",
    "                    if self.n_copies == 1:     \n",
    "                        density_each_row = density_each_row\n",
    "                    else:\n",
    "                        density_each_row_copy = density_each_row\n",
    "                        for u in range(self.n_copies - 1):\n",
    "                            density_each_row = np.kron(density_each_row, density_each_row_copy)\n",
    "                        \n",
    "                    # Calculate trace of the dot product of density of each row and sum of projectors \n",
    "                    # with corresponding positive and negative eigenvalues respectively    \n",
    "                    trace_class_split[k] = np.einsum('ij,ji->', density_each_row, self.proj_sum_[i])\n",
    "                return trace_class_split\n",
    "            \n",
    "            # Calculate trace values for each class, per subset split\n",
    "            trace_class = Parallel(n_jobs = self.n_jobs) \\\n",
    "                          (delayed(trace_split_func)(j) for j in range(self.n_splits))\n",
    "            return np.concatenate(trace_class, axis = 0)\n",
    "            \n",
    "        # Calculate trace values for each class\n",
    "        trace_matrix = np.transpose(Parallel(n_jobs = self.n_jobs) \\\n",
    "                                   (delayed(trace_func)(i) for i in range(2)))\n",
    "        return trace_matrix\n",
    "        \n",
    "    \n",
    "    # Function for predict\n",
    "    def predict(self, X):\n",
    "        \"\"\"Performs HQC classification on X and returns the binary classes.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The input samples. An array of int or float.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self.classes_[predict_trace_index] : array-like, shape (n_samples,)\n",
    "            The predicted binary classes. An array of str, int or float.\n",
    "        \"\"\"\n",
    "        # Determine column index with the higher trace value in trace_matrix\n",
    "        # If both columns have the same trace value, returns column index 0\n",
    "        predict_trace_index = np.argmax(self.predict_proba(X), axis = 1)\n",
    "        # Returns the predicted binary classes\n",
    "        return self.classes_[predict_trace_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appendicitis dataset (7 features, 106 rows)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('appendicitis.tsv',delimiter='\\t')\n",
    "X = df.drop('target', axis=1).values\n",
    "y = df['target'].values\n",
    "\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7520661157024794, 0.8772542482734037)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check F1 score and Helstrom bound values for various rescale and n_copies values\n",
    "model = hqc(rescale=0.5, n_copies=3, encoding='stereo', class_wgt='weighted', n_jobs=-1, n_splits=2).fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.f1_score(y_test, y_hat, average='weighted'), model.hels_bound_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 ms ± 3.53 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=1\n",
    "%timeit hqc(rescale=0.5, n_copies=1, encoding='stereo', class_wgt='weighted', n_jobs=-1, n_splits=2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291 ms ± 15 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=2\n",
    "%timeit hqc(rescale=0.5, n_copies=2, encoding='stereo', class_wgt='weighted', n_jobs=-1, n_splits=2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.92 s ± 70.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=3\n",
    "%timeit hqc(rescale=0.5, n_copies=3, encoding='stereo', class_wgt='weighted', n_jobs=-1, n_splits=2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10min 49s ± 52.5 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=4\n",
    "%timeit hqc(rescale=0.5, n_copies=4, encoding='stereo', class_wgt='weighted', n_jobs=-1, n_splits=2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# banana dataset (2 features, 5300 rows)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('banana.tsv', sep='\\t')\n",
    "X = df.drop('target', axis=1).values\n",
    "y = df['target'].values\n",
    "\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.858978398722441, 0.7732939055876817)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check F1 score and Helstrom bound values for various rescale and n_copies values\n",
    "model = hqc(rescale=0.5, n_copies=4, encoding='stereo', class_wgt='weighted', n_jobs=-1, n_splits=2).fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.f1_score(y_test, y_hat, average='weighted'), model.hels_bound_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259 ms ± 2.77 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=1\n",
    "%timeit hqc(rescale=0.5, n_copies=1, encoding='stereo', class_wgt='weighted', n_jobs=-1, n_splits=2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515 ms ± 42.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=2\n",
    "%timeit hqc(rescale=0.5, n_copies=2, encoding='stereo', class_wgt='weighted', n_jobs=-1, n_splits=2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919 ms ± 50.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=3\n",
    "%timeit hqc(rescale=0.5, n_copies=3, encoding='stereo', class_wgt='weighted', n_jobs=-1, n_splits=2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.89 s ± 70.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=4\n",
    "%timeit hqc(rescale=0.5, n_copies=4, encoding='stereo', class_wgt='weighted', n_jobs=-1, n_splits=2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.57 s ± 144 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=5\n",
    "%timeit hqc(rescale=0.5, n_copies=5, encoding='stereo', class_wgt='weighted', n_jobs=-1, n_splits=2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 1s ± 890 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=6\n",
    "%timeit hqc(rescale=0.5, n_copies=6, encoding='stereo', class_wgt='weighted', n_jobs=-1, n_splits=2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10min 21s ± 9.6 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=7\n",
    "%timeit hqc(rescale=0.5, n_copies=7, encoding='stereo', class_wgt='weighted', n_jobs=-1, n_splits=2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
