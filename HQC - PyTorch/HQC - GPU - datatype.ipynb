{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HQC - GPU 4.ipynb","provenance":[],"authorship_tag":"ABX9TyNz7B/BGCiv8MBGyJArY4Hs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ulW25TZpVBQX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598505134854,"user_tz":-600,"elapsed":2384,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}}},"source":["### This is a GPU implementation for the HQC classifier using Scikit-learn's methods, but with PyTorch as the backend. ###"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_L6DEBHVHP3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598505134856,"user_tz":-600,"elapsed":2369,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}}},"source":["# I have implemented the code below in such a way that you would only need to input X and y as numpy arrays and the\n","# output y_hat would also be a numpy array (rather than PyTorch tensors). This would make it easier to use the package\n","# below with minimal knowledge of PyTorch tensors.\n","\n","# Take note of the parameter n_splits, where the implementation of n_splits now is different to the one in the CPU case.\n","# Please read the description of n_splits below."],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"RwGkI93ZLjQ9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598593219909,"user_tz":-600,"elapsed":2489,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}}},"source":["import numpy as np\n","from sklearn.base import BaseEstimator, ClassifierMixin\n","from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n","from sklearn.utils.multiclass import check_classification_targets\n","import torch\n","from torch.nn.functional import normalize\n","\n","class HQC(BaseEstimator, ClassifierMixin):\n","    \"\"\"The Helstrom Quantum Centroid (HQC) classifier is a quantum-inspired supervised \n","    classification approach for data with binary classes (ie. data with 2 classes only).\n","                         \n","    Parameters\n","    ----------\n","    rescale : int or float, default = 1\n","        The dataset rescaling factor. A parameter used for rescaling the dataset. \n","    encoding : str, default = 'amplit'\n","        The encoding method used to encode vectors into quantum densities. Possible values:\n","        'amplit', 'stereo'. 'amplit' means using the amplitude encoding method. 'stereo' means \n","        using the inverse of the standard stereographic projection encoding method. Default set \n","        to 'amplit'.\n","    n_copies : int, default = 1\n","        The number of copies to take for each quantum density. This is equivalent to taking \n","        the n-fold Kronecker tensor product for each quantum density.\n","    class_wgt : str, default = 'equi'\n","        The class weights assigned to the Quantum Helstrom observable terms. Possible values: \n","        'equi', 'weighted'. 'equi' means assigning equal weights of 1/2 (equiprobable) to the\n","        two classes in the Quantum Helstrom observable. 'weighted' means assigning weights equal \n","        to the proportion of the number of rows in each class to the two classes in the Quantum \n","        Helstrom observable. Default set to 'equi'.\n","    n_splits : int, default = 1\n","        The number of subset splits performed on the input dataset row-wise and on the number \n","        of eigenvalues/eigenvectors of the Quantum Helstrom observable for optimal speed \n","        performance. If 1 is given, no subset splits are used. For optimal speed, recommend \n","        using small values as close to 1 as possible. If memory blow-out occurs, increase \n","        n_splits.\n","    dtype : torch.float32 or torch.float64, default = torch.float64\n","        The float datatype used for the elements in the Pytorch tensor dataset. Datatype has to\n","        be of float to ensure calculations are done in float rather than integer. To achieve\n","        higher n_copies without memory blow-out issues, reduce float precision, which may or may   \n","        not affect accuracy.\n","    \n","    Attributes\n","    ----------\n","    classes_ : ndarray, shape (2,)\n","        Sorted binary classes.\n","    centroids_ : tensor, size (2, (n_features + 1)**n_copies, (n_features + 1)**n_copies)\n","        Quantum Centroids for class with index 0 and 1 respectively. Stored in GPU.\n","    hels_obs_ : tensor, size ((n_features + 1)**n_copies, (n_features + 1)**n_copies)\n","        Quantum Helstrom observable. Stored in GPU.\n","    proj_sums_ : tensor, size (2, (n_features + 1)**n_copies, (n_features + 1)**n_copies)\n","        Sum of the projectors of the Quantum Helstrom observable's eigenvectors, which has\n","        corresponding positive and negative eigenvalues respectively. Stored in GPU.\n","    hels_bound_ : float\n","        Helstrom bound is the upper bound of the probability that one can correctly \n","        discriminate whether a quantum density is of which of the two binary quantum density \n","        pattern. Stored in CPU.         \n","    \"\"\"\n","    # Added binary_only tag as required by sklearn check_estimator\n","    def _more_tags(self):\n","        return {'binary_only': True}        \n","    \n","    \n","    # Initialize model hyperparameters\n","    def __init__(self, \n","                 rescale = 1,\n","                 encoding = 'amplit',\n","                 n_copies = 1,                   \n","                 class_wgt = 'equi', \n","                 n_splits = 1,\n","                 dtype = torch.float64):\n","        self.rescale = rescale\n","        self.encoding = encoding\n","        self.n_copies = n_copies\n","        self.class_wgt = class_wgt\n","        self.n_splits = n_splits\n","        self.dtype = dtype\n","        \n","        # Raise error if dtype is not torch.float32 or torch.float64\n","        if self.dtype not in [torch.float32, torch.float64]:\n","            raise ValueError('dtype should be torch.float32 or torch.float64 only')\n","        \n","    \n","    # Function for kronecker tensor product of PyTorch tensors, set as global function\n","    global kronecker\n","    def kronecker(A, B):\n","        return torch.einsum('nab,ncd->nacbd', A, B).view(A.size(0), \n","                                                         A.size(1)*B.size(1), \n","                                                         A.size(2)*B.size(2))\n","    \n","    \n","    # Function for fit\n","    def fit(self, X, y):\n","        \"\"\"Perform HQC classification with the inverse of the standard stereographic \n","        projection encoding, with the option to rescale the dataset prior to encoding.\n","                \n","        Parameters\n","        ----------\n","        X : array-like, shape (n_samples, n_features)\n","            The training input samples. An array of int or float.\n","        y : array-like, shape (n_samples,)\n","            The training input binary target values. An array of str, int or float.\n","            \n","        Returns\n","        -------\n","        self : object\n","            Returns self.\n","        \"\"\"\n","        # Check that arrays X and y have correct shape\n","        X, y = check_X_y(X, y)\n","        \n","        # Ensure target array y is of non-regression type  \n","        # Added as required by sklearn check_estimator\n","        check_classification_targets(y)\n","            \n","        # Store binary classes and encode y into binary class indexes 0 and 1\n","        self.classes_, y_class_index = np.unique(y, return_inverse = True)\n","        \n","        # Cast array X into a floating point tensor to ensure all following calculations below  \n","        # are done in float rather than integer, and send tensor X from CPU to GPU\n","        X = torch.tensor(X, dtype = self.dtype).cuda()\n","        \n","        # Rescale X\n","        X = self.rescale*X\n","        \n","        # Calculate sum of squares of each row (sample) in X\n","        X_sq_sum = (X**2).sum(dim = 1)\n","        \n","        # Number of rows in X\n","        m = X.shape[0]\n","        \n","        # Number of columns in X\n","        n = X.shape[1]\n","        \n","        # Calculate X' using amplitude or inverse of the standard stereographic projection \n","        # encoding method\n","        if self.encoding == 'amplit':\n","            X_prime = normalize(torch.cat([X, torch.ones(m, dtype = self.dtype) \\\n","                                           .reshape(-1, 1).cuda()], dim = 1), p = 2, dim = 1)\n","        elif self.encoding == 'stereo':\n","            X_prime = (1 / (X_sq_sum + 1)).reshape(-1, 1)*(torch.cat((2*X, (X_sq_sum - 1) \\\n","                                                                      .reshape(-1, 1)), dim = 1))\n","        else:\n","            raise ValueError('encoding should be \"amplit\" or \"stereo\"')\n","        \n","        # Number of columns in X', set as global variable\n","        global n_prime\n","        n_prime = n + 1\n","        \n","        # Function to calculate terms in the Quantum Centroids and quantum Helstrom \n","        # observable for each class, per subset split\n","        def centroids_terms_func(i):\n","            # Cast array y_class_index into a tensor and send from CPU to GPU\n","            # Determine rows (samples) in X' belonging to either class\n","            X_prime_class = X_prime[torch.CharTensor(y_class_index).cuda() == i]\n","                                    \n","            # Split X' belonging to either class into n_splits subsets, row-wise\n","            # Send tensors from GPU to CPU and cast tensors into arrays, use np.array_split()\n","            # because the equivalent torch.chunk() doesn't behave similarly to np.array_split()\n","            X_prime_class_split_arr = np.array_split(X_prime_class.cpu().numpy(),\n","                                                     indices_or_sections = self.n_splits,\n","                                                     axis = 0)\n","            \n","            # Cast arrays back to tensors and send back from CPU to GPU\n","            X_prime_class_split = [torch.tensor(a, dtype = self.dtype).cuda() \n","                                   for a in X_prime_class_split_arr]\n","            \n","            # Function to calculate sum of quantum densities belonging to each class, \n","            # per subset split\n","            def X_prime_class_split_func(j):\n","                # Counter for j-th split of X'\n","                X_prime_class_split_jth = X_prime_class_split[j]\n","                \n","                # Number of rows (samples) in j-th split of X'\n","                m_class_split = X_prime_class_split_jth.shape[0]\n","                \n","                # Encode vectors into quantum densities\n","                density_chunk = torch.matmul(X_prime_class_split_jth.view(m_class_split, \n","                                                                          n_prime, 1),\n","                                             X_prime_class_split_jth.view(m_class_split, \n","                                                                          1, n_prime))\n","                \n","                # Calculate n-fold Kronecker tensor product\n","                if self.n_copies == 1:\n","                    density_chunk = density_chunk\n","                else:\n","                    density_chunk_copy = density_chunk\n","                    for b in range(self.n_copies - 1):\n","                        density_chunk = kronecker(density_chunk, density_chunk_copy)\n","                    \n","                # Calculate sum of quantum densities\n","                density_chunk_sum = density_chunk.sum(dim = 0)\n","                return density_chunk_sum\n","\n","            # Number of rows/columns in density matrix, set as global variable\n","            global density_nrow_ncol\n","            density_nrow_ncol = n_prime**self.n_copies\n","            \n","            # Initialize array density_class_sum\n","            density_class_sum = torch.zeros([density_nrow_ncol, density_nrow_ncol], \n","                                            dtype = self.dtype).cuda()\n","            for c in range(self.n_splits):\n","                # Calculate sum of quantum densities belonging to either class\n","                density_class_sum = density_class_sum + X_prime_class_split_func(c)\n","            \n","            # Number of rows (samples) in X' belonging to either class\n","            m_class = X_prime_class.shape[0]\n","            \n","            # Function to calculate centroid belonging to either class\n","            def centroid():\n","                # Calculate Quantum Centroid belonging to either class\n","                # Added ZeroDivisionError as required by sklearn check_estimator\n","                try:\n","                    centroid = (1 / m_class)*density_class_sum\n","                except ZeroDivisionError:\n","                    centroid = 0 \n","                return centroid\n","            \n","            # Calculate centroid belonging to either class\n","            centroid_class = centroid()\n","            \n","            # Calculate terms in the quantum Helstrom observable belonging to either class\n","            if self.class_wgt == 'equi':\n","                hels_obs_terms = 0.5*centroid_class\n","            elif self.class_wgt == 'weighted':\n","                hels_obs_terms = (m_class / m)*centroid_class\n","            else:\n","                raise ValueError('class_wgt should be \"equi\" or \"weighted\"')\n","            return m_class, centroid_class, hels_obs_terms\n","        \n","        # Calculate Quantum Centroids and terms in the quantum Helstrom observable belonging \n","        # to either class\n","        centroids_terms = [centroids_terms_func(0), centroids_terms_func(1)] \n","                    \n","        # Determine Quantum Centroids\n","        self.centroids_ = torch.stack([centroids_terms[0][1], centroids_terms[1][1]], dim = 0)\n","                \n","        # Calculate quantum Helstrom observable\n","        self.hels_obs_ = centroids_terms[0][2] - centroids_terms[1][2] \n","                \n","        # Calculate eigenvalues w and eigenvectors v of the quantum Helstrom observable\n","        w, v = torch.symeig(self.hels_obs_, eigenvectors = True)\n","          \n","        # Length of w\n","        len_w = len(w)\n","        \n","        # Initialize array eigval_class\n","        eigval_class = torch.empty_like(w, dtype = self.dtype).cuda()\n","        for d in range(len_w):\n","            # Create an array of 0s and 1s to indicate positive and negative eigenvalues\n","            # respectively\n","            if w[d] > 0:\n","                eigval_class[d] = 0\n","            else:\n","                eigval_class[d] = 1\n","        \n","        # Transpose matrix v containing eigenvectors to row-wise\n","        eigvec = v.T\n","        \n","        # Function to calculate sum of the projectors corresponding to positive and negative\n","        # eigenvalues respectively\n","        def sum_proj_func(e):\n","            # Split eigenvectors belonging to positive or negative eigenvalues into n_splits subsets\n","            # Send tensors from GPU to CPU and cast tensors into arrays, use np.array_split()\n","            # because the equivalent torch.chunk() doesn't behave similarly to np.array_split()\n","            eigvec_class_split_arr_full = np.array_split(eigvec.cpu().numpy()[eigval_class.cpu() == e],\n","                                                         indices_or_sections = self.n_splits,\n","                                                         axis = 0)\n","            \n","            # Remove empty rows in eigvec_class_split_arr_full\n","            eigvec_class_split_arr = [f for f in eigvec_class_split_arr_full if f.shape[0] > 0]\n","\n","            # Cast arrays back to tensors and send back from CPU to GPU\n","            eigvec_class_split = [torch.tensor(g, dtype = self.dtype).cuda() \n","                                  for g in eigvec_class_split_arr]             \n","            \n","            # Function to calculate sum of the projectors corresponding to positive and negative\n","            # eigenvalues respectively, per subset split\n","            def eigvec_class_split_func(h):\n","                # Counter for h-th split of eigvec\n","                eigvec_class_split_hth = eigvec_class_split[h]\n","                \n","                # Number of rows (samples) in h-th split of eigvec\n","                m_eigvec_class_split = eigvec_class_split_hth.shape[0]\n","                \n","                # Calculate projectors corresponding to positive and negative eigenvalues  \n","                # respectively, per subset split\n","                proj_split = torch.matmul(eigvec_class_split_hth.view(m_eigvec_class_split, \n","                                                                      density_nrow_ncol, 1),\n","                                          eigvec_class_split_hth.view(m_eigvec_class_split, \n","                                                                      1, density_nrow_ncol))\n","                \n","                # Calculate sum of projectors\n","                proj_split_sum = proj_split.sum(dim = 0)\n","                return proj_split_sum\n","            \n","            # Determine length of eigvec_class_split_arr\n","            eigvec_class_split_arr_len = len(eigvec_class_split_arr)\n","\n","            # Initialize array proj_class_sum\n","            proj_class_sum = torch.zeros([density_nrow_ncol, density_nrow_ncol], \n","                                         dtype = self.dtype).cuda()  \n","            for k in range(eigvec_class_split_arr_len):\n","                # Calculate sum of the projectors corresponding to positive and negative eigenvalues\n","                # respectively\n","                proj_class_sum = proj_class_sum + eigvec_class_split_func(k)\n","            return proj_class_sum\n","        \n","        # Calculate sum of the projectors corresponding to positive and negative eigenvalues \n","        # respectively\n","        self.proj_sums_ = torch.stack([sum_proj_func(0), sum_proj_func(1)], dim = 0)        \n","                       \n","        # Calculate Helstrom bound\n","        self.hels_bound_ = (centroids_terms[0][0] / m)*torch.einsum('ij,ji->', self.centroids_[0], \n","                                                                   self.proj_sums_[0]).item() \\\n","                           + (centroids_terms[1][0] / m)*torch.einsum('ij,ji->', self.centroids_[1], \n","                                                                     self.proj_sums_[1]).item()\n","        return self\n","        \n","    \n","    # Function for predict_proba\n","    def predict_proba(self, X):\n","        \"\"\"Performs HQC classification on X and returns the trace of the dot product of the densities \n","        and the sum of the projectors with corresponding positive and negative eigenvalues respectively.\n","        \n","        Parameters\n","        ----------\n","        X : array-like, shape (n_samples, n_features)\n","            The input samples. An array of int or float.       \n","            \n","        Returns\n","        -------\n","        trace_matrix : tensor, size (n_samples, 2)\n","            Column index 0 corresponds to the trace of the dot product of the densities and the sum  \n","            of projectors with positive eigenvalues. Column index 1 corresponds to the trace of the  \n","            dot product of the densities and the sum of projectors with negative eigenvalues. A tensor \n","            of float. Stored in GPU.\n","        \"\"\"\n","        # Send tensor self.proj_sums_ from GPU to CPU and cast into an array\n","        self.proj_sums_arr_ = self.proj_sums_.cpu().numpy()\n","                \n","        # Check if fit had been called\n","        check_is_fitted(self, ['proj_sums_arr_'])\n","               \n","        # Input validation of array X\n","        X = check_array(X)\n","                 \n","        # Cast array X into a floating point tensor to ensure all following calculations below  \n","        # are done in float rather than integer, and send tensor X from CPU to GPU\n","        X = torch.tensor(X, dtype = self.dtype).cuda()\n","        \n","        # Rescale X\n","        X = self.rescale*X        \n","        \n","        # Calculate sum of squares of each row (sample) in X\n","        X_sq_sum = (X**2).sum(dim = 1)\n","        \n","        # Number of rows in X\n","        m = X.shape[0]\n","        \n","        # Number of columns in X\n","        n = X.shape[1]\n","\n","        # Calculate X' using amplitude or inverse of the standard stereographic projection \n","        # encoding method\n","        if self.encoding == 'amplit':\n","            X_prime = normalize(torch.cat([X, torch.ones(m, dtype = self.dtype) \\\n","                                           .reshape(-1, 1).cuda()], dim = 1), p = 2, dim = 1)\n","        elif self.encoding == 'stereo':\n","            X_prime = (1 / (X_sq_sum + 1)).reshape(-1, 1)*(torch.cat((2*X, (X_sq_sum - 1) \\\n","                                                                      .reshape(-1, 1)), dim = 1))\n","        else:\n","            raise ValueError('encoding should be \"amplit\" or \"stereo\"')\n","                       \n","        # Function to calculate trace values for each class\n","        def trace_func(i):\n","            # Split X' into n_splits subsets, row-wise\n","            # Send tensors from GPU to CPU and cast tensors into arrays, use np.array_split()\n","            # because the equivalent torch.chunk() doesn't behave similarly to np.array_split()\n","            X_prime_split_arr_full = np.array_split(X_prime.cpu().numpy(),\n","                                                    indices_or_sections = self.n_splits,\n","                                                    axis = 0)\n","            \n","            # Remove empty rows in X_prime_split_arr_full\n","            X_prime_split_arr = [a for a in X_prime_split_arr_full if a.shape[0] > 0]\n","\n","            # Cast arrays back to tensors and send back from CPU to GPU\n","            X_prime_split = [torch.tensor(q, dtype = self.dtype).cuda() for q in X_prime_split_arr]\n","            \n","            # Function to calculate trace values for each class, per subset split\n","            def trace_split_func(j):\n","                # Counter for j-th split X'\n","                X_prime_split_jth = X_prime_split[j]\n","                \n","                # Number of rows (samples) in j-th split X'\n","                X_prime_split_m = X_prime_split_jth.shape[0]\n","                \n","                # Encode vectors into quantum densities\n","                density_chunk = torch.matmul(X_prime_split_jth.view(X_prime_split_m, n_prime, 1),\n","                                             X_prime_split_jth.view(X_prime_split_m, 1, n_prime))\n","                \n","                # Calculate n-fold Kronecker tensor product\n","                if self.n_copies == 1:\n","                    density_chunk = density_chunk\n","                else:\n","                    density_chunk_copy = density_chunk\n","                    for b in range(self.n_copies - 1):\n","                        density_chunk = kronecker(density_chunk, density_chunk_copy)\n","                        \n","                # Calculate trace of the dot product of density of each row and sum of projectors\n","                # with corresponding positive and negative eigenvalues respectively\n","                return torch.einsum('bij,ji->b', density_chunk, self.proj_sums_[i])\n","            \n","            # Determine length of X_prime_split_arr\n","            X_prime_split_arr_len = len(X_prime_split_arr)\n","\n","            # Initialize array trace_class\n","            trace_class = torch.empty([0], dtype = self.dtype).cuda()\n","            for c in range(X_prime_split_arr_len):\n","                # Calculate trace values for each class, per subset split\n","                trace_class = torch.cat([trace_class, trace_split_func(c)], dim = 0)\n","            return trace_class\n","        \n","        # Calculate trace values for each class\n","        trace_matrix = torch.stack([trace_func(0), trace_func(1)], dim = 1)\n","        return trace_matrix\n","                \n","    \n","    # Function for predict\n","    def predict(self, X):\n","        \"\"\"Performs HQC classification on X and returns the binary classes.\n","        \n","        Parameters\n","        ----------\n","        X : array-like, shape (n_samples, n_features)\n","            The input samples. An array of int or float.\n","            \n","        Returns\n","        -------\n","        self.classes_[predict_trace_index] : array-like, shape (n_samples,)\n","            The predicted binary classes. An array of str, int or float.\n","        \"\"\"\n","        # Determine column index with the higher trace value in trace_matrix\n","        # If both columns have the same trace value, returns column index 1, which is different \n","        # to np.argmax() which returns column index 0\n","        predict_trace_index = torch.argmax(self.predict_proba(X), axis = 1)\n","        # Returns the predicted binary classes\n","        return self.classes_[predict_trace_index.cpu().numpy()]"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"BfCvqD-AVOOE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598593243362,"user_tz":-600,"elapsed":1015,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}}},"source":["# appendicitis dataset (7 features, 106 rows)\n","import pandas as pd\n","\n","df = pd.read_csv('appendicitis.tsv',delimiter='\\t')\n","X = df.drop('target', axis=1).values\n","y = df['target'].values\n","\n","from sklearn import model_selection\n","X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=4)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOJrt6BKXc-Y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598505745957,"user_tz":-600,"elapsed":1089,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}},"outputId":"4a67d959-77bd-4e49-a18d-9a4a1dcbc2c8"},"source":["# No. of rows in training and test sets\n","X_train.shape[0], X_test.shape[0]"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(84, 22)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"Bfk7t-yNXflT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598593355298,"user_tz":-600,"elapsed":5414,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}},"outputId":"8c5dd4a9-e265-41ce-a8f9-e359541f27b3"},"source":["# Check F1 score and Helstrom bound values for various rescale and n_copies values\n","model = HQC(rescale=0.5, n_copies=4, encoding='stereo', class_wgt='weighted', n_splits=60, dtype = torch.float32).fit(X_train, y_train)\n","y_hat = model.predict(X_test)\n","\n","from sklearn import metrics\n","metrics.f1_score(y_test, y_hat, average='weighted'), model.hels_bound_"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.7520661157024794, 0.8835998872915904)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"MW6A6dDTXiE5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598506993469,"user_tz":-600,"elapsed":3064,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}},"outputId":"67063fb2-aa75-4ed0-f048-0de93acdd0f6"},"source":["# Time required for n_copies=1\n","%timeit HQC(rescale=0.5, n_copies=1, encoding='stereo', class_wgt='weighted', n_splits=1, dtype = torch.float32).fit(X_train, y_train)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["100 loops, best of 3: 5.04 ms per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SM64T88VcPqP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598507029875,"user_tz":-600,"elapsed":5425,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}},"outputId":"4ac0993b-7982-474a-d6b6-8d9a959fadd9"},"source":["# Time required for n_copies=2\n","%timeit HQC(rescale=0.5, n_copies=2, encoding='stereo', class_wgt='weighted', n_splits=1, dtype = torch.float32).fit(X_train, y_train)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["100 loops, best of 3: 10.9 ms per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zeWYFzdhcX-Y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598507060204,"user_tz":-600,"elapsed":4794,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}},"outputId":"892f9629-41bc-4916-c27e-c3e5f13f009b"},"source":["# Time required for n_copies=3\n","%timeit HQC(rescale=0.5, n_copies=3, encoding='stereo', class_wgt='weighted', n_splits=1, dtype = torch.float32).fit(X_train, y_train)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["10 loops, best of 3: 92.8 ms per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4znh8A-Wcfir","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598507109902,"user_tz":-600,"elapsed":28301,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}},"outputId":"8776af26-10f9-45ef-c4b4-594bb3277b02"},"source":["# Time required for n_copies=4\n","%timeit HQC(rescale=0.5, n_copies=4, encoding='stereo', class_wgt='weighted', n_splits=60, dtype = torch.float32).fit(X_train, y_train)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["1 loop, best of 3: 6.79 s per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-BHAQ0vJcl70","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":442},"executionInfo":{"status":"error","timestamp":1598590034918,"user_tz":-600,"elapsed":2728,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}},"outputId":"132c8b1b-1330-4feb-b60f-bdf6a8e7c52d"},"source":["# Time required for n_copies=5\n","# No. of rows in training set = 84\n","%timeit HQC(rescale=0.5, n_copies=5, encoding='stereo', class_wgt='weighted', n_splits=84, dtype = torch.float32).fit(X_train, y_train)"],"execution_count":5,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-e6878a3fa7aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Time required for n_copies=5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# No. of rows in training set = 84\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"timeit HQC(rescale=0.5, n_copies=5, encoding='stereo', class_wgt='weighted', n_splits=84, dtype = torch.float32).fit(X_train, y_train)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m                 \u001b[0mworst_tuning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworst_tuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n","\u001b[0;32m<ipython-input-2-40e8bef193d1>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;31m# Calculate Quantum Centroids and terms in the quantum Helstrom observable belonging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;31m# to either class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mcentroids_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcentroids_terms_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids_terms_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;31m# Determine Quantum Centroids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-40e8bef193d1>\u001b[0m in \u001b[0;36mcentroids_terms_func\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0;31m# Calculate sum of quantum densities belonging to either class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                 \u001b[0mdensity_class_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdensity_class_sum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX_prime_class_split_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;31m# Number of rows (samples) in X' belonging to either class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-40e8bef193d1>\u001b[0m in \u001b[0;36mX_prime_class_split_func\u001b[0;34m(j)\u001b[0m\n\u001b[1;32m    184\u001b[0m                     \u001b[0mdensity_chunk_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdensity_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_copies\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                         \u001b[0mdensity_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkronecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdensity_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity_chunk_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;31m# Calculate sum of quantum densities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-40e8bef193d1>\u001b[0m in \u001b[0;36mkronecker\u001b[0;34m(A, B)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mkronecker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkronecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         return torch.einsum('nab,ncd->nacbd', A, B).view(A.size(0), \n\u001b[0m\u001b[1;32m     87\u001b[0m                                                          \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                                                          A.size(2)*B.size(2))\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 14.73 GiB total capacity; 12.06 GiB already allocated; 1.79 GiB free; 12.06 GiB reserved in total by PyTorch)"]}]},{"cell_type":"code","metadata":{"id":"vgqa1OUDeF9Q","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t95JphjHeyO7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598593620539,"user_tz":-600,"elapsed":1021,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}}},"source":["# banana dataset (2 features, 5300 rows)\n","import pandas as pd\n","\n","df = pd.read_csv('banana.tsv', sep='\\t')\n","X = df.drop('target', axis=1).values\n","y = df['target'].values\n","\n","from sklearn import model_selection\n","X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=4)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"2mq7GucCezH7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598507670020,"user_tz":-600,"elapsed":1054,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}},"outputId":"88d92219-e0a7-4211-9bc9-b0865b2c770a"},"source":["# No. of rows in training and test sets\n","X_train.shape[0], X_test.shape[0]"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4240, 1060)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"ANbjdWO4e1VQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598594570236,"user_tz":-600,"elapsed":78166,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}},"outputId":"08b63f3c-ac9f-4712-977b-3c4383957089"},"source":["# Check F1 score and Helstrom bound values for various rescale and n_copies values\n","model = HQC(rescale=1, n_copies=8, encoding='stereo', class_wgt='equi', n_splits=3000, dtype = torch.float32).fit(X_train, y_train)\n","y_hat = model.predict(X_test)\n","\n","from sklearn import metrics\n","metrics.f1_score(y_test, y_hat, average='weighted'), model.hels_bound_"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.8068654145017903, 0.7737680824578932)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"TOF9zFoxe4lq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598507822991,"user_tz":-600,"elapsed":3283,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}},"outputId":"3891c592-5fdc-4106-ec07-c0fd47d37acc"},"source":["# Time required for n_copies=1\n","%timeit HQC(rescale=0.5, n_copies=1, encoding='stereo', class_wgt='weighted', n_splits=1, dtype = torch.float32).fit(X_train, y_train)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["100 loops, best of 3: 5.01 ms per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JOgFDZ_zfaIP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598507849272,"user_tz":-600,"elapsed":3369,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}},"outputId":"f11a8fde-eccc-446c-d58b-661f7945c17f"},"source":["# Time required for n_copies=2\n","%timeit HQC(rescale=0.5, n_copies=2, encoding='stereo', class_wgt='weighted', n_splits=1, dtype = torch.float32).fit(X_train, y_train)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["100 loops, best of 3: 5.71 ms per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fs72-fetfgh7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598507879801,"user_tz":-600,"elapsed":4314,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}},"outputId":"5beae668-50cb-4895-b2b9-606c3fff845d"},"source":["# Time required for n_copies=3\n","%timeit HQC(rescale=0.5, n_copies=3, encoding='stereo', class_wgt='weighted', n_splits=1, dtype = torch.float32).fit(X_train, y_train)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["100 loops, best of 3: 7.96 ms per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ssfDBYNFfnwj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598507901706,"user_tz":-600,"elapsed":1444,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}},"outputId":"6858b6f9-d116-4150-b03c-23b16077f6c8"},"source":["# Time required for n_copies=4\n","%timeit HQC(rescale=0.5, n_copies=4, encoding='stereo', class_wgt='weighted', n_splits=1, dtype = torch.float32).fit(X_train, y_train)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["10 loops, best of 3: 19.2 ms per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HUrFpTxkftzf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598507933273,"user_tz":-600,"elapsed":4380,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}},"outputId":"c007985b-a819-4b98-89f3-1ef310343f9d"},"source":["# Time required for n_copies=5\n","%timeit HQC(rescale=0.5, n_copies=5, encoding='stereo', class_wgt='weighted', n_splits=1, dtype = torch.float32).fit(X_train, y_train)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["10 loops, best of 3: 79 ms per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cy5huWIzf0y0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598508473744,"user_tz":-600,"elapsed":3271,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}},"outputId":"2497a7c7-0a77-4011-de21-dd25d1207290"},"source":["# Time required for n_copies=6\n","%timeit HQC(rescale=0.5, n_copies=6, encoding='stereo', class_wgt='weighted', n_splits=2, dtype = torch.float32).fit(X_train, y_train)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["1 loop, best of 3: 520 ms per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lx3U-iq0f9AA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598508520255,"user_tz":-600,"elapsed":20966,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}},"outputId":"fac109ef-eedc-43a9-c81b-077749160c68"},"source":["# Time required for n_copies=7\n","%timeit HQC(rescale=0.5, n_copies=7, encoding='stereo', class_wgt='weighted', n_splits=18, dtype = torch.float32).fit(X_train, y_train)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["1 loop, best of 3: 4.97 s per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p2rsOt4xiACE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598509052586,"user_tz":-600,"elapsed":499876,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}},"outputId":"8bda1ff6-bec9-4022-aaaf-00fcb0dfebb3"},"source":["# Time required for n_copies=8\n","%timeit HQC(rescale=0.5, n_copies=8, encoding='stereo', class_wgt='weighted', n_splits=3000, dtype = torch.float32).fit(X_train, y_train)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["1 loop, best of 3: 2min 4s per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"09rwHJ-liNFg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":425},"executionInfo":{"status":"error","timestamp":1598587994120,"user_tz":-600,"elapsed":319486,"user":{"displayName":"Leo Chow","photoUrl":"","userId":"14333577283681602670"}},"outputId":"a129612f-512f-4ae8-895f-218e19226d5b"},"source":["# Time required for n_copies=9\n","# No. of rows in training set = 4240\n","%timeit HQC(rescale=0.5, n_copies=9, encoding='stereo', class_wgt='weighted', n_splits=4240, dtype = torch.float32).fit(X_train, y_train)"],"execution_count":7,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-62825b3ba6ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Time required for n_copies=9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# No. of rows in training set = 4240\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"timeit HQC(rescale=0.5, n_copies=9, encoding='stereo', class_wgt='weighted', n_splits=4240, dtype = torch.float32).fit(X_train, y_train)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m                 \u001b[0mworst_tuning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworst_tuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n","\u001b[0;32m<ipython-input-2-cc49bace17d0>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# Calculate eigenvalues w and eigenvectors v of the quantum Helstrom observable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymeig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhels_obs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigenvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# Length of w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"]}]},{"cell_type":"code","metadata":{"id":"jA6uFcU4kdSm","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}