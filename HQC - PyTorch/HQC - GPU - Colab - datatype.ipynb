{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2384,
     "status": "ok",
     "timestamp": 1598505134854,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "ulW25TZpVBQX"
   },
   "outputs": [],
   "source": [
    "### This is a GPU implementation for the HQC classifier using Scikit-learn's methods, but with PyTorch as the backend. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2369,
     "status": "ok",
     "timestamp": 1598505134856,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "P_L6DEBHVHP3"
   },
   "outputs": [],
   "source": [
    "# I have implemented the code below in such a way that you would only need to input X and y as numpy arrays and the\n",
    "# output y_hat would also be a numpy array (rather than PyTorch tensors). This would make it easier to use the package\n",
    "# below with minimal knowledge of PyTorch tensors.\n",
    "\n",
    "# Take note of the parameter n_splits, where the implementation of n_splits now is different to the one in the CPU case.\n",
    "# Please read the description of n_splits below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1728,
     "status": "ok",
     "timestamp": 1598967822900,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "RwGkI93ZLjQ9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "import torch\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "class HQC(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"The Helstrom Quantum Centroid (HQC) classifier is a quantum-inspired supervised \n",
    "    classification approach for data with binary classes (ie. data with 2 classes only).\n",
    "                         \n",
    "    Parameters\n",
    "    ----------\n",
    "    rescale : int or float, default = 1\n",
    "        The dataset rescaling factor. A parameter used for rescaling the dataset. \n",
    "    encoding : str, default = 'amplit'\n",
    "        The encoding method used to encode vectors into quantum densities. Possible values:\n",
    "        'amplit', 'stereo'. 'amplit' means using the amplitude encoding method. 'stereo' means \n",
    "        using the inverse of the standard stereographic projection encoding method. Default set \n",
    "        to 'amplit'.\n",
    "    n_copies : int, default = 1\n",
    "        The number of copies to take for each quantum density. This is equivalent to taking \n",
    "        the n-fold Kronecker tensor product for each quantum density.\n",
    "    class_wgt : str, default = 'equi'\n",
    "        The class weights assigned to the Quantum Helstrom observable terms. Possible values: \n",
    "        'equi', 'weighted'. 'equi' means assigning equal weights of 1/2 (equiprobable) to the\n",
    "        two classes in the Quantum Helstrom observable. 'weighted' means assigning weights equal \n",
    "        to the proportion of the number of rows in each class to the two classes in the Quantum \n",
    "        Helstrom observable. Default set to 'equi'.\n",
    "    n_splits : int, default = 1\n",
    "        The number of subset splits performed on the input dataset row-wise and on the number \n",
    "        of eigenvalues/eigenvectors of the Quantum Helstrom observable for optimal speed \n",
    "        performance. If 1 is given, no splits are performed. For optimal speed, recommend \n",
    "        using small values as close to 1 as possible. If memory blow-out occurs, increase \n",
    "        n_splits.\n",
    "    dtype : torch.float32 or torch.float64, default = torch.float64\n",
    "        The float datatype used for the elements in the Pytorch tensor dataset. Datatype has to\n",
    "        be of float to ensure calculations are done in float rather than integer. To achieve\n",
    "        higher n_copies without memory blow-out issues, reduce float precision, which may or may   \n",
    "        not affect accuracy.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : ndarray, shape (2,)\n",
    "        Sorted binary classes.\n",
    "    centroids_ : tensor, size (2, (n_features + 1)**n_copies, (n_features + 1)**n_copies)\n",
    "        Quantum Centroids for class with index 0 and 1 respectively. Stored in GPU.\n",
    "    hels_obs_ : tensor, size ((n_features + 1)**n_copies, (n_features + 1)**n_copies)\n",
    "        Quantum Helstrom observable. Stored in GPU.\n",
    "    proj_sums_ : tensor, size (2, (n_features + 1)**n_copies, (n_features + 1)**n_copies)\n",
    "        Sum of the projectors of the Quantum Helstrom observable's eigenvectors, which has\n",
    "        corresponding positive and negative eigenvalues respectively. Stored in GPU.\n",
    "    hels_bound_ : float\n",
    "        Helstrom bound is the upper bound of the probability that one can correctly \n",
    "        discriminate whether a quantum density is of which of the two binary quantum density \n",
    "        pattern. Stored in CPU.         \n",
    "    \"\"\"\n",
    "    # Added binary_only tag as required by sklearn check_estimator\n",
    "    def _more_tags(self):\n",
    "        return {'binary_only': True}        \n",
    "    \n",
    "    \n",
    "    # Initialize model hyperparameters\n",
    "    def __init__(self, \n",
    "                 rescale = 1,\n",
    "                 encoding = 'amplit',\n",
    "                 n_copies = 1,                   \n",
    "                 class_wgt = 'equi', \n",
    "                 n_splits = 1,\n",
    "                 dtype = torch.float64):\n",
    "        self.rescale = rescale\n",
    "        self.encoding = encoding\n",
    "        self.n_copies = n_copies\n",
    "        self.class_wgt = class_wgt\n",
    "        self.n_splits = n_splits\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        # Raise error if dtype is not torch.float32 or torch.float64\n",
    "        if self.dtype not in [torch.float32, torch.float64]:\n",
    "            raise ValueError('dtype should be torch.float32 or torch.float64 only')\n",
    "        \n",
    "    \n",
    "    # Function for kronecker tensor product of PyTorch tensors, set as global function\n",
    "    global kronecker\n",
    "    def kronecker(A, B):\n",
    "        return torch.einsum('nab,ncd->nacbd', A, B).view(A.size(0), \n",
    "                                                         A.size(1)*B.size(1), \n",
    "                                                         A.size(2)*B.size(2))\n",
    "    \n",
    "    \n",
    "    # Function for fit\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Perform HQC classification with the inverse of the standard stereographic \n",
    "        projection encoding, with the option to rescale the dataset prior to encoding.\n",
    "                \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The training input samples. An array of int or float.\n",
    "        y : array-like, shape (n_samples,)\n",
    "            The training input binary target values. An array of str, int or float.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        # Check that arrays X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        # Ensure target array y is of non-regression type  \n",
    "        # Added as required by sklearn check_estimator\n",
    "        check_classification_targets(y)\n",
    "            \n",
    "        # Store binary classes and encode y into binary class indexes 0 and 1\n",
    "        self.classes_, y_class_index = np.unique(y, return_inverse = True)\n",
    "\n",
    "        # Raise error if there are more than 2 classes\n",
    "        if len(self.classes_) > 2:  \n",
    "            raise ValueError('only 2 classes are supported')\n",
    "        \n",
    "        # Cast array X into a floating point tensor to ensure all following calculations below  \n",
    "        # are done in float rather than integer, and send tensor X from CPU to GPU\n",
    "        X = torch.tensor(X, dtype = self.dtype).cuda()\n",
    "        \n",
    "        # Rescale X\n",
    "        X = self.rescale*X\n",
    "        \n",
    "        # Calculate sum of squares of each row (sample) in X\n",
    "        X_sq_sum = (X**2).sum(dim = 1)\n",
    "        \n",
    "        # Number of rows in X\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Number of columns in X\n",
    "        n = X.shape[1]\n",
    "        \n",
    "        # Calculate X' using amplitude or inverse of the standard stereographic projection \n",
    "        # encoding method\n",
    "        if self.encoding == 'amplit':\n",
    "            X_prime = normalize(torch.cat([X, torch.ones(m, dtype = self.dtype) \\\n",
    "                                           .reshape(-1, 1).cuda()], dim = 1), p = 2, dim = 1)\n",
    "        elif self.encoding == 'stereo':\n",
    "            X_prime = (1 / (X_sq_sum + 1)).reshape(-1, 1)*(torch.cat((2*X, (X_sq_sum - 1) \\\n",
    "                                                                      .reshape(-1, 1)), dim = 1))\n",
    "        else:\n",
    "            raise ValueError('encoding should be \"amplit\" or \"stereo\"')\n",
    "        \n",
    "        # Number of columns in X', set as global variable\n",
    "        global n_prime\n",
    "        n_prime = n + 1\n",
    "        \n",
    "        # Function to calculate terms in the Quantum Centroids and quantum Helstrom \n",
    "        # observable for each class, per subset split\n",
    "        def centroids_terms_func(i):\n",
    "            # Cast array y_class_index into a tensor and send from CPU to GPU\n",
    "            # Determine rows (samples) in X' belonging to either class\n",
    "            X_prime_class = X_prime[torch.CharTensor(y_class_index).cuda() == i]\n",
    "                                    \n",
    "            # Split X' belonging to either class into n_splits subsets, row-wise\n",
    "            # Send tensors from GPU to CPU and cast tensors into arrays, use np.array_split()\n",
    "            # because the equivalent torch.chunk() doesn't behave similarly to np.array_split()\n",
    "            X_prime_class_split_arr = np.array_split(X_prime_class.cpu().numpy(),\n",
    "                                                     indices_or_sections = self.n_splits,\n",
    "                                                     axis = 0)\n",
    "            \n",
    "            # Cast arrays back to tensors and send back from CPU to GPU\n",
    "            X_prime_class_split = [torch.tensor(a, dtype = self.dtype).cuda() \n",
    "                                   for a in X_prime_class_split_arr]\n",
    "            \n",
    "            # Function to calculate sum of quantum densities belonging to each class, \n",
    "            # per subset split\n",
    "            def X_prime_class_split_func(j):\n",
    "                # Counter for j-th split of X'\n",
    "                X_prime_class_split_jth = X_prime_class_split[j]\n",
    "                \n",
    "                # Number of rows (samples) in j-th split of X'\n",
    "                m_class_split = X_prime_class_split_jth.shape[0]\n",
    "                \n",
    "                # Encode vectors into quantum densities\n",
    "                density_chunk = torch.matmul(X_prime_class_split_jth.view(m_class_split, \n",
    "                                                                          n_prime, 1),\n",
    "                                             X_prime_class_split_jth.view(m_class_split, \n",
    "                                                                          1, n_prime))\n",
    "                \n",
    "                # Calculate n-fold Kronecker tensor product\n",
    "                if self.n_copies == 1:\n",
    "                    density_chunk = density_chunk\n",
    "                else:\n",
    "                    density_chunk_copy = density_chunk\n",
    "                    for b in range(self.n_copies - 1):\n",
    "                        density_chunk = kronecker(density_chunk, density_chunk_copy)\n",
    "                    \n",
    "                # Calculate sum of quantum densities\n",
    "                density_chunk_sum = density_chunk.sum(dim = 0)\n",
    "                return density_chunk_sum\n",
    "\n",
    "            # Number of rows/columns in density matrix, set as global variable\n",
    "            global density_nrow_ncol\n",
    "            density_nrow_ncol = n_prime**self.n_copies\n",
    "            \n",
    "            # Initialize array density_class_sum\n",
    "            density_class_sum = torch.zeros([density_nrow_ncol, density_nrow_ncol], \n",
    "                                            dtype = self.dtype).cuda()\n",
    "            for c in range(self.n_splits):\n",
    "                # Calculate sum of quantum densities belonging to either class\n",
    "                density_class_sum = density_class_sum + X_prime_class_split_func(c)\n",
    "            \n",
    "            # Number of rows (samples) in X' belonging to either class\n",
    "            m_class = X_prime_class.shape[0]\n",
    "            \n",
    "            # Function to calculate centroid belonging to either class\n",
    "            def centroid():\n",
    "                # Calculate Quantum Centroid belonging to either class\n",
    "                # Added ZeroDivisionError as required by sklearn check_estimator\n",
    "                try:\n",
    "                    centroid = (1 / m_class)*density_class_sum\n",
    "                except ZeroDivisionError:\n",
    "                    centroid = 0 \n",
    "                return centroid\n",
    "            \n",
    "            # Calculate centroid belonging to either class\n",
    "            centroid_class = centroid()\n",
    "            \n",
    "            # Calculate terms in the quantum Helstrom observable belonging to either class\n",
    "            if self.class_wgt == 'equi':\n",
    "                hels_obs_terms = 0.5*centroid_class\n",
    "            elif self.class_wgt == 'weighted':\n",
    "                hels_obs_terms = (m_class / m)*centroid_class\n",
    "            else:\n",
    "                raise ValueError('class_wgt should be \"equi\" or \"weighted\"')\n",
    "            return m_class, centroid_class, hels_obs_terms\n",
    "        \n",
    "        # Calculate Quantum Centroids and terms in the quantum Helstrom observable belonging \n",
    "        # to either class\n",
    "        centroids_terms = [centroids_terms_func(0), centroids_terms_func(1)] \n",
    "                    \n",
    "        # Determine Quantum Centroids\n",
    "        self.centroids_ = torch.stack([centroids_terms[0][1], centroids_terms[1][1]], dim = 0)\n",
    "                \n",
    "        # Calculate quantum Helstrom observable\n",
    "        self.hels_obs_ = centroids_terms[0][2] - centroids_terms[1][2] \n",
    "                \n",
    "        # Calculate eigenvalues w and eigenvectors v of the quantum Helstrom observable\n",
    "        w, v = torch.symeig(self.hels_obs_, eigenvectors = True)\n",
    "          \n",
    "        # Length of w\n",
    "        len_w = len(w)\n",
    "        \n",
    "        # Initialize array eigval_class\n",
    "        eigval_class = torch.empty_like(w, dtype = self.dtype).cuda()\n",
    "        for d in range(len_w):\n",
    "            # Create an array of 0s and 1s to indicate positive and negative eigenvalues\n",
    "            # respectively\n",
    "            if w[d] > 0:\n",
    "                eigval_class[d] = 0\n",
    "            else:\n",
    "                eigval_class[d] = 1\n",
    "        \n",
    "        # Transpose matrix v containing eigenvectors to row-wise\n",
    "        eigvec = v.T\n",
    "        \n",
    "        # Function to calculate sum of the projectors corresponding to positive and negative\n",
    "        # eigenvalues respectively\n",
    "        def sum_proj_func(e):\n",
    "            # Split eigenvectors belonging to positive or negative eigenvalues into n_splits subsets\n",
    "            # Send tensors from GPU to CPU and cast tensors into arrays, use np.array_split()\n",
    "            # because the equivalent torch.chunk() doesn't behave similarly to np.array_split()\n",
    "            eigvec_class_split_arr_full = np.array_split(eigvec.cpu().numpy()[eigval_class.cpu() == e],\n",
    "                                                         indices_or_sections = self.n_splits,\n",
    "                                                         axis = 0)\n",
    "            \n",
    "            # Remove empty rows in eigvec_class_split_arr_full\n",
    "            eigvec_class_split_arr = [f for f in eigvec_class_split_arr_full if f.shape[0] > 0]\n",
    "\n",
    "            # Cast arrays back to tensors and send back from CPU to GPU\n",
    "            eigvec_class_split = [torch.tensor(g, dtype = self.dtype).cuda() \n",
    "                                  for g in eigvec_class_split_arr]             \n",
    "            \n",
    "            # Function to calculate sum of the projectors corresponding to positive and negative\n",
    "            # eigenvalues respectively, per subset split\n",
    "            def eigvec_class_split_func(h):\n",
    "                # Counter for h-th split of eigvec\n",
    "                eigvec_class_split_hth = eigvec_class_split[h]\n",
    "                \n",
    "                # Number of rows (samples) in h-th split of eigvec\n",
    "                m_eigvec_class_split = eigvec_class_split_hth.shape[0]\n",
    "                \n",
    "                # Calculate projectors corresponding to positive and negative eigenvalues  \n",
    "                # respectively, per subset split\n",
    "                proj_split = torch.matmul(eigvec_class_split_hth.view(m_eigvec_class_split, \n",
    "                                                                      density_nrow_ncol, 1),\n",
    "                                          eigvec_class_split_hth.view(m_eigvec_class_split, \n",
    "                                                                      1, density_nrow_ncol))\n",
    "                \n",
    "                # Calculate sum of projectors\n",
    "                proj_split_sum = proj_split.sum(dim = 0)\n",
    "                return proj_split_sum\n",
    "            \n",
    "            # Determine length of eigvec_class_split_arr\n",
    "            eigvec_class_split_arr_len = len(eigvec_class_split_arr)\n",
    "\n",
    "            # Initialize array proj_class_sum\n",
    "            proj_class_sum = torch.zeros([density_nrow_ncol, density_nrow_ncol], \n",
    "                                         dtype = self.dtype).cuda()  \n",
    "            for k in range(eigvec_class_split_arr_len):\n",
    "                # Calculate sum of the projectors corresponding to positive and negative eigenvalues\n",
    "                # respectively\n",
    "                proj_class_sum = proj_class_sum + eigvec_class_split_func(k)\n",
    "            return proj_class_sum\n",
    "        \n",
    "        # Calculate sum of the projectors corresponding to positive and negative eigenvalues \n",
    "        # respectively\n",
    "        self.proj_sums_ = torch.stack([sum_proj_func(0), sum_proj_func(1)], dim = 0)        \n",
    "                       \n",
    "        # Calculate Helstrom bound\n",
    "        self.hels_bound_ = (centroids_terms[0][0] / m)*torch.einsum('ij,ji->', self.centroids_[0], \n",
    "                                                                   self.proj_sums_[0]).item() \\\n",
    "                           + (centroids_terms[1][0] / m)*torch.einsum('ij,ji->', self.centroids_[1], \n",
    "                                                                     self.proj_sums_[1]).item()\n",
    "        return self\n",
    "        \n",
    "    \n",
    "    # Function for predict_proba\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Performs HQC classification on X and returns the trace of the dot product of the densities \n",
    "        and the sum of the projectors with corresponding positive and negative eigenvalues respectively.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The input samples. An array of int or float.       \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        trace_matrix : array-like, shape (n_samples, 2)\n",
    "            Column index 0 corresponds to the trace of the dot product of the densities and the sum  \n",
    "            of projectors with positive eigenvalues. Column index 1 corresponds to the trace of the  \n",
    "            dot product of the densities and the sum of projectors with negative eigenvalues. An array \n",
    "            of float.\n",
    "        \"\"\"\n",
    "        # Send tensor self.proj_sums_ from GPU to CPU and cast into an array\n",
    "        self.proj_sums_arr_ = self.proj_sums_.cpu().numpy()\n",
    "                \n",
    "        # Check if fit had been called\n",
    "        check_is_fitted(self, ['proj_sums_arr_'])\n",
    "               \n",
    "        # Input validation of array X\n",
    "        X = check_array(X)\n",
    "                 \n",
    "        # Cast array X into a floating point tensor to ensure all following calculations below  \n",
    "        # are done in float rather than integer, and send tensor X from CPU to GPU\n",
    "        X = torch.tensor(X, dtype = self.dtype).cuda()\n",
    "        \n",
    "        # Rescale X\n",
    "        X = self.rescale*X        \n",
    "        \n",
    "        # Calculate sum of squares of each row (sample) in X\n",
    "        X_sq_sum = (X**2).sum(dim = 1)\n",
    "        \n",
    "        # Number of rows in X\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Number of columns in X\n",
    "        n = X.shape[1]\n",
    "\n",
    "        # Calculate X' using amplitude or inverse of the standard stereographic projection \n",
    "        # encoding method\n",
    "        if self.encoding == 'amplit':\n",
    "            X_prime = normalize(torch.cat([X, torch.ones(m, dtype = self.dtype) \\\n",
    "                                           .reshape(-1, 1).cuda()], dim = 1), p = 2, dim = 1)\n",
    "        elif self.encoding == 'stereo':\n",
    "            X_prime = (1 / (X_sq_sum + 1)).reshape(-1, 1)*(torch.cat((2*X, (X_sq_sum - 1) \\\n",
    "                                                                      .reshape(-1, 1)), dim = 1))\n",
    "        else:\n",
    "            raise ValueError('encoding should be \"amplit\" or \"stereo\"')\n",
    "                       \n",
    "        # Function to calculate trace values for each class\n",
    "        def trace_func(i):\n",
    "            # Split X' into n_splits subsets, row-wise\n",
    "            # Send tensors from GPU to CPU and cast tensors into arrays, use np.array_split()\n",
    "            # because the equivalent torch.chunk() doesn't behave similarly to np.array_split()\n",
    "            X_prime_split_arr_full = np.array_split(X_prime.cpu().numpy(),\n",
    "                                                    indices_or_sections = self.n_splits,\n",
    "                                                    axis = 0)\n",
    "            \n",
    "            # Remove empty rows in X_prime_split_arr_full\n",
    "            X_prime_split_arr = [a for a in X_prime_split_arr_full if a.shape[0] > 0]\n",
    "\n",
    "            # Cast arrays back to tensors and send back from CPU to GPU\n",
    "            X_prime_split = [torch.tensor(q, dtype = self.dtype).cuda() for q in X_prime_split_arr]\n",
    "            \n",
    "            # Function to calculate trace values for each class, per subset split\n",
    "            def trace_split_func(j):\n",
    "                # Counter for j-th split X'\n",
    "                X_prime_split_jth = X_prime_split[j]\n",
    "                \n",
    "                # Number of rows (samples) in j-th split X'\n",
    "                X_prime_split_m = X_prime_split_jth.shape[0]\n",
    "                \n",
    "                # Encode vectors into quantum densities\n",
    "                density_chunk = torch.matmul(X_prime_split_jth.view(X_prime_split_m, n_prime, 1),\n",
    "                                             X_prime_split_jth.view(X_prime_split_m, 1, n_prime))\n",
    "                \n",
    "                # Calculate n-fold Kronecker tensor product\n",
    "                if self.n_copies == 1:\n",
    "                    density_chunk = density_chunk\n",
    "                else:\n",
    "                    density_chunk_copy = density_chunk\n",
    "                    for b in range(self.n_copies - 1):\n",
    "                        density_chunk = kronecker(density_chunk, density_chunk_copy)\n",
    "                        \n",
    "                # Calculate trace of the dot product of density of each row and sum of projectors\n",
    "                # with corresponding positive and negative eigenvalues respectively\n",
    "                return torch.einsum('bij,ji->b', density_chunk, self.proj_sums_[i])\n",
    "            \n",
    "            # Determine length of X_prime_split_arr\n",
    "            X_prime_split_arr_len = len(X_prime_split_arr)\n",
    "\n",
    "            # Initialize array trace_class\n",
    "            trace_class = torch.empty([0], dtype = self.dtype).cuda()\n",
    "            for c in range(X_prime_split_arr_len):\n",
    "                # Calculate trace values for each class, per subset split\n",
    "                trace_class = torch.cat([trace_class, trace_split_func(c)], dim = 0)\n",
    "            return trace_class\n",
    "        \n",
    "        # Calculate trace values for each class, send from GPU to CPU and cast into an array\n",
    "        trace_matrix = torch.stack([trace_func(0), trace_func(1)], dim = 1).cpu().numpy()\n",
    "        return trace_matrix\n",
    "                \n",
    "    \n",
    "    # Function for predict\n",
    "    def predict(self, X):\n",
    "        \"\"\"Performs HQC classification on X and returns the binary classes.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The input samples. An array of int or float.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self.classes_[predict_trace_index] : array-like, shape (n_samples,)\n",
    "            The predicted binary classes. An array of str, int or float.\n",
    "        \"\"\"\n",
    "        # Determine column index with the higher trace value in trace_matrix\n",
    "        # Cast predict_proba(X) from an array into a tensor and send from CPU to GPU\n",
    "        # If both columns have the same trace value, returns column index 1, which is different \n",
    "        # to np.argmax() which returns column index 0\n",
    "        predict_trace_index = torch.argmax(torch.tensor(self.predict_proba(X),\n",
    "                                                        dtype = self.dtype).cuda(), axis = 1)\n",
    "        # Returns the predicted binary classes, send tensor from GPU to CPU and cast tensor\n",
    "        # into an array\n",
    "        return self.classes_[predict_trace_index.cpu().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1015,
     "status": "ok",
     "timestamp": 1598593243362,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "BfCvqD-AVOOE"
   },
   "outputs": [],
   "source": [
    "# appendicitis dataset (7 features, 106 rows)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('appendicitis.tsv',delimiter='\\t')\n",
    "X = df.drop('target', axis=1).values\n",
    "y = df['target'].values\n",
    "\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1089,
     "status": "ok",
     "timestamp": 1598505745957,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "hOJrt6BKXc-Y",
    "outputId": "4a67d959-77bd-4e49-a18d-9a4a1dcbc2c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 22)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No. of rows in training and test sets\n",
    "X_train.shape[0], X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5414,
     "status": "ok",
     "timestamp": 1598593355298,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "Bfk7t-yNXflT",
    "outputId": "8c5dd4a9-e265-41ce-a8f9-e359541f27b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7520661157024794, 0.8835998872915904)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check F1 score and Helstrom bound values for various rescale and n_copies values\n",
    "model = HQC(rescale=0.5, n_copies=4, encoding='stereo', class_wgt='weighted', n_splits=60, dtype = torch.float32).fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.f1_score(y_test, y_hat, average='weighted'), model.hels_bound_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3064,
     "status": "ok",
     "timestamp": 1598506993469,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "MW6A6dDTXiE5",
    "outputId": "67063fb2-aa75-4ed0-f048-0de93acdd0f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 5.04 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=1\n",
    "%timeit HQC(rescale=0.5, n_copies=1, encoding='stereo', class_wgt='weighted', n_splits=1, dtype = torch.float32).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5425,
     "status": "ok",
     "timestamp": 1598507029875,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "SM64T88VcPqP",
    "outputId": "4ac0993b-7982-474a-d6b6-8d9a959fadd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 10.9 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=2\n",
    "%timeit HQC(rescale=0.5, n_copies=2, encoding='stereo', class_wgt='weighted', n_splits=1, dtype = torch.float32).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4794,
     "status": "ok",
     "timestamp": 1598507060204,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "zeWYFzdhcX-Y",
    "outputId": "892f9629-41bc-4916-c27e-c3e5f13f009b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 92.8 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=3\n",
    "%timeit HQC(rescale=0.5, n_copies=3, encoding='stereo', class_wgt='weighted', n_splits=1, dtype = torch.float32).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28301,
     "status": "ok",
     "timestamp": 1598507109902,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "4znh8A-Wcfir",
    "outputId": "8776af26-10f9-45ef-c4b4-594bb3277b02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 6.79 s per loop\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=4\n",
    "%timeit HQC(rescale=0.5, n_copies=4, encoding='stereo', class_wgt='weighted', n_splits=60, dtype = torch.float32).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2728,
     "status": "error",
     "timestamp": 1598590034918,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "-BHAQ0vJcl70",
    "outputId": "132c8b1b-1330-4feb-b60f-bdf6a8e7c52d"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e6878a3fa7aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Time required for n_copies=5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# No. of rows in training set = 84\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"timeit HQC(rescale=0.5, n_copies=5, encoding='stereo', class_wgt='weighted', n_splits=84, dtype = torch.float32).fit(X_train, y_train)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m                 \u001b[0mworst_tuning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworst_tuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-40e8bef193d1>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;31m# Calculate Quantum Centroids and terms in the quantum Helstrom observable belonging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;31m# to either class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mcentroids_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcentroids_terms_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids_terms_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;31m# Determine Quantum Centroids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-40e8bef193d1>\u001b[0m in \u001b[0;36mcentroids_terms_func\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0;31m# Calculate sum of quantum densities belonging to either class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                 \u001b[0mdensity_class_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdensity_class_sum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX_prime_class_split_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;31m# Number of rows (samples) in X' belonging to either class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-40e8bef193d1>\u001b[0m in \u001b[0;36mX_prime_class_split_func\u001b[0;34m(j)\u001b[0m\n\u001b[1;32m    184\u001b[0m                     \u001b[0mdensity_chunk_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdensity_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_copies\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                         \u001b[0mdensity_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkronecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdensity_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity_chunk_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;31m# Calculate sum of quantum densities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-40e8bef193d1>\u001b[0m in \u001b[0;36mkronecker\u001b[0;34m(A, B)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mkronecker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkronecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         return torch.einsum('nab,ncd->nacbd', A, B).view(A.size(0), \n\u001b[0m\u001b[1;32m     87\u001b[0m                                                          \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                                                          A.size(2)*B.size(2))\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 14.73 GiB total capacity; 12.06 GiB already allocated; 1.79 GiB free; 12.06 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=5\n",
    "# No. of rows in training set = 84\n",
    "%timeit HQC(rescale=0.5, n_copies=5, encoding='stereo', class_wgt='weighted', n_splits=84, dtype = torch.float32).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vgqa1OUDeF9Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 799,
     "status": "ok",
     "timestamp": 1598967859009,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "t95JphjHeyO7"
   },
   "outputs": [],
   "source": [
    "# banana dataset (2 features, 5300 rows)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('banana.tsv', sep='\\t')\n",
    "X = df.drop('target', axis=1).values\n",
    "y = df['target'].values\n",
    "\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1054,
     "status": "ok",
     "timestamp": 1598507670020,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "2mq7GucCezH7",
    "outputId": "88d92219-e0a7-4211-9bc9-b0865b2c770a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4240, 1060)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No. of rows in training and test sets\n",
    "X_train.shape[0], X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78166,
     "status": "ok",
     "timestamp": 1598594570236,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "ANbjdWO4e1VQ",
    "outputId": "08b63f3c-ac9f-4712-977b-3c4383957089"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8068654145017903, 0.7737680824578932)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check F1 score and Helstrom bound values for various rescale and n_copies values\n",
    "model = HQC(rescale=1, n_copies=8, encoding='stereo', class_wgt='equi', n_splits=3000, dtype = torch.float32).fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.f1_score(y_test, y_hat, average='weighted'), model.hels_bound_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3283,
     "status": "ok",
     "timestamp": 1598507822991,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "TOF9zFoxe4lq",
    "outputId": "3891c592-5fdc-4106-ec07-c0fd47d37acc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 5.01 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=1\n",
    "%timeit HQC(rescale=0.5, n_copies=1, encoding='stereo', class_wgt='weighted', n_splits=1, dtype = torch.float32).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3369,
     "status": "ok",
     "timestamp": 1598507849272,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "JOgFDZ_zfaIP",
    "outputId": "f11a8fde-eccc-446c-d58b-661f7945c17f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 5.71 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=2\n",
    "%timeit HQC(rescale=0.5, n_copies=2, encoding='stereo', class_wgt='weighted', n_splits=1, dtype = torch.float32).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4314,
     "status": "ok",
     "timestamp": 1598507879801,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "fs72-fetfgh7",
    "outputId": "5beae668-50cb-4895-b2b9-606c3fff845d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 7.96 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=3\n",
    "%timeit HQC(rescale=0.5, n_copies=3, encoding='stereo', class_wgt='weighted', n_splits=1, dtype = torch.float32).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1444,
     "status": "ok",
     "timestamp": 1598507901706,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "ssfDBYNFfnwj",
    "outputId": "6858b6f9-d116-4150-b03c-23b16077f6c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 19.2 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=4\n",
    "%timeit HQC(rescale=0.5, n_copies=4, encoding='stereo', class_wgt='weighted', n_splits=1, dtype = torch.float32).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4380,
     "status": "ok",
     "timestamp": 1598507933273,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "HUrFpTxkftzf",
    "outputId": "c007985b-a819-4b98-89f3-1ef310343f9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 79 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=5\n",
    "%timeit HQC(rescale=0.5, n_copies=5, encoding='stereo', class_wgt='weighted', n_splits=1, dtype = torch.float32).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3271,
     "status": "ok",
     "timestamp": 1598508473744,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "cy5huWIzf0y0",
    "outputId": "2497a7c7-0a77-4011-de21-dd25d1207290"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 520 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=6\n",
    "%timeit HQC(rescale=0.5, n_copies=6, encoding='stereo', class_wgt='weighted', n_splits=2, dtype = torch.float32).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20966,
     "status": "ok",
     "timestamp": 1598508520255,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "Lx3U-iq0f9AA",
    "outputId": "fac109ef-eedc-43a9-c81b-077749160c68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 4.97 s per loop\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=7\n",
    "%timeit HQC(rescale=0.5, n_copies=7, encoding='stereo', class_wgt='weighted', n_splits=18, dtype = torch.float32).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 499876,
     "status": "ok",
     "timestamp": 1598509052586,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "p2rsOt4xiACE",
    "outputId": "8bda1ff6-bec9-4022-aaaf-00fcb0dfebb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 2min 4s per loop\n"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=8\n",
    "%timeit HQC(rescale=0.5, n_copies=8, encoding='stereo', class_wgt='weighted', n_splits=3000, dtype = torch.float32).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 319486,
     "status": "error",
     "timestamp": 1598587994120,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "09rwHJ-liNFg",
    "outputId": "a129612f-512f-4ae8-895f-218e19226d5b"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-62825b3ba6ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Time required for n_copies=9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# No. of rows in training set = 4240\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"timeit HQC(rescale=0.5, n_copies=9, encoding='stereo', class_wgt='weighted', n_splits=4240, dtype = torch.float32).fit(X_train, y_train)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m                 \u001b[0mworst_tuning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworst_tuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-cc49bace17d0>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# Calculate eigenvalues w and eigenvectors v of the quantum Helstrom observable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymeig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhels_obs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigenvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# Length of w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "# Time required for n_copies=9\n",
    "# No. of rows in training set = 4240\n",
    "%timeit HQC(rescale=0.5, n_copies=9, encoding='stereo', class_wgt='weighted', n_splits=4240, dtype = torch.float32).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jA6uFcU4kdSm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1887,
     "status": "ok",
     "timestamp": 1598968038681,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "eWv50o0m4f0a"
   },
   "outputs": [],
   "source": [
    "# Using scikit-learn's GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'rescale':[0.5, 1, 1.5], 'encoding':['amplit', 'stereo'], 'n_copies':[1, 2], 'class_wgt':['equi', 'weighted']}\n",
    "models = GridSearchCV(HQC(n_splits=1, dtype=torch.float32), param_grid).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 736,
     "status": "ok",
     "timestamp": 1598968043344,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "2t2Xom2p4kpM",
    "outputId": "e5aa1ba7-8a0c-47b2-d51f-53e4ce60e12f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7867484392554756, 0.6852296184818699)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best F1 score\n",
    "best_model = models.best_estimator_\n",
    "y_hat = best_model.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.f1_score(y_test, y_hat, average='weighted'), best_model.hels_bound_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 660,
     "status": "ok",
     "timestamp": 1598968048897,
     "user": {
      "displayName": "Leo Chow",
      "photoUrl": "",
      "userId": "14333577283681602670"
     },
     "user_tz": -600
    },
    "id": "vIRNEuEf4lo4",
    "outputId": "6f4ee92f-24f1-4709-882c-7bce97f68a6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_wgt': 'equi', 'encoding': 'amplit', 'n_copies': 2, 'rescale': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best hyperparameter combination\n",
    "models.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HjhDjfcZ7ClY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOhpgJvr2tHKVa/Updl9MvM",
   "name": "HQC - GPU 4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
