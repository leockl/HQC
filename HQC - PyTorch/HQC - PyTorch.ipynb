{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HQC estimator below accepts Pytorch tensors (stored in CPU) for both feature matrix X and target vector y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "from sklearn.preprocessing import normalize\n",
    "# from joblib import Parallel, delayed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.multiprocessing import Pool\n",
    "\n",
    "class HQC(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"The Helstrom Quantum Centroid (HQC) classifier is a quantum-inspired supervised \n",
    "    classification approach for data with binary classes (ie. data with 2 classes only).\n",
    "                         \n",
    "    Parameters\n",
    "    ----------\n",
    "    rescale : int or float, default = 1\n",
    "        The dataset rescaling factor. A parameter used for rescaling the dataset. \n",
    "    n_copies : int, default = 1\n",
    "        The number of copies to take for each quantum density. This is equivalent to taking \n",
    "        the n-fold Kronecker tensor product for each quantum density.\n",
    "    encoding : str, default = 'amplit'\n",
    "        The encoding method used to encode vectors into quantum densities. Possible values:\n",
    "        'amplit', 'stereo'. 'amplit' means using the amplitude encoding method. 'stereo' means \n",
    "        using the inverse of the standard stereographic projection encoding method. Default set \n",
    "        to 'amplit'.\n",
    "    class_wgt : str, default = 'equi'\n",
    "        The class weights assigned to the Quantum Helstrom observable terms. Possible values: \n",
    "        'equi', 'weighted'. 'equi' means assigning equal weights of 1/2 (equiprobable) to the\n",
    "        two classes in the Quantum Helstrom observable. 'weighted' means assigning weights equal \n",
    "        to the proportion of the number of rows in each class to the two classes in the Quantum \n",
    "        Helstrom observable. Default set to 'equi'.\n",
    "    n_jobs : int, default = None\n",
    "        The number of CPU cores used when parallelizing. If -1 all CPUs are used. If 1 is given, \n",
    "        no parallel computing code is used at all. For n_jobs below -1, (n_cpus + 1 + n_jobs) \n",
    "        are used. Thus for n_jobs = -2, all CPUs but one are used. None is a marker for ‘unset’ \n",
    "        that will be interpreted as n_jobs = 1.\n",
    "    n_splits : int, default = 1\n",
    "        The number of subset splits performed on the input dataset row-wise and on the number \n",
    "        of eigenvalues/eigenvectors of the Quantum Helstrom observable for optimal speed \n",
    "        performance. If 1 is given, no splits are used. For optimal speed, recommend using \n",
    "        n_splits = int(numpy.ceil(number of CPU cores used/2)). If memory blow-out occurs, \n",
    "        reduce n_splits.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : ndarray, shape (2,)\n",
    "        Sorted binary classes.\n",
    "    centroid_ : ndarray, shape (2, n_features + 1, n_features + 1)\n",
    "        Quantum Centroids for class with index 0 and 1 respectively.\n",
    "    q_hels_obs_ : ndarray, shape (n_features + 1, n_features + 1)\n",
    "        Quantum Helstrom observable.\n",
    "    proj_sum_ : tuple, shape (2, n_features + 1, n_features + 1)\n",
    "        Sum of the projectors of the Quantum Helstrom observable's eigenvectors, which has\n",
    "        corresponding positive and negative eigenvalues respectively.\n",
    "    hels_bound_ : float\n",
    "        Helstrom bound is the upper bound of the probability that one can correctly \n",
    "        discriminate whether a quantum density is of which of the two binary quantum density \n",
    "        pattern.          \n",
    "    \"\"\"\n",
    "    # Added binary_only tag as required by sklearn check_estimator\n",
    "    def _more_tags(self):\n",
    "        return {'binary_only': True}\n",
    "    \n",
    "    \n",
    "    # Initialize model hyperparameters\n",
    "    def __init__(self, \n",
    "                 rescale = 1, \n",
    "                 n_copies = 1, \n",
    "                 encoding = 'amplit', \n",
    "                 class_wgt = 'equi', \n",
    "                 n_jobs = None, \n",
    "                 n_splits = 1):\n",
    "        self.rescale = rescale\n",
    "        self.n_copies = n_copies\n",
    "        self.encoding = encoding\n",
    "        self.class_wgt = class_wgt\n",
    "        self.n_jobs = n_jobs\n",
    "        self.n_splits = n_splits\n",
    "        \n",
    "    \n",
    "    # Function for kronecker tensor product for PyTorch tensors\n",
    "    def kronecker(A, B):\n",
    "        return torch.einsum('ab,cd->acbd', A, B).view(A.size(0)*B.size(0), A.size(1)*B.size(1))\n",
    "    \n",
    "    \n",
    "    # Function for fit\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Perform HQC classification with the inverse of the standard stereographic \n",
    "        projection encoding, with the option to rescale the dataset prior to encoding.\n",
    "                \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The training input samples. An array of int or float.\n",
    "        y : array-like, shape (n_samples,)\n",
    "            The training input binary target values. An array of str, int or float.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        # Cast tensors X and y into arrays\n",
    "        X_arr = X.numpy()\n",
    "        y_arr = y.numpy()\n",
    "        \n",
    "        # Check that X and y have correct shape\n",
    "        # X, y = check_X_y(X, y)\n",
    "        X_arr, y_arr = check_X_y(X_arr, y_arr)\n",
    "        \n",
    "        # Ensure target y is of non-regression type  \n",
    "        # Added as required by sklearn check_estimator\n",
    "        # check_classification_targets(y)\n",
    "        check_classification_targets(y_arr)\n",
    "            \n",
    "        # Send tensor y from CPU to GPU, store binary classes and encode y into binary class\n",
    "        # indexes 0 and 1\n",
    "        # self.classes_, y_class_index = np.unique(y, return_inverse = True)\n",
    "        self.classes_, y_class_index = torch.unique(y.cuda(), return_inverse = True)\n",
    "        \n",
    "        # Cast X to float to ensure all following calculations below are done in float  \n",
    "        # rather than integer, and send tensor X from CPU to GPU\n",
    "        # X = X.astype(float)\n",
    "        X = torch.DoubleTensor(X).cuda()\n",
    "        \n",
    "        # Rescale X\n",
    "        X = self.rescale*X\n",
    "        \n",
    "        # Calculate sum of squares of each row (sample) in X\n",
    "        # X_sq_sum = (X**2).sum(axis = 1)\n",
    "        X_sq_sum = (X**2).sum(dim = 1)\n",
    "        \n",
    "        # Number of rows in X\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Number of columns in X\n",
    "        n = X.shape[1]\n",
    "        \n",
    "        # Calculate X' using amplitude or inverse of the standard stereographic projection \n",
    "        # encoding method\n",
    "        if self.encoding == 'amplit':\n",
    "            # X_prime = normalize(np.concatenate((X, np.ones(m).reshape(-1, 1)), axis = 1))\n",
    "            X_prime = nn.functional.normalize(torch.cat([X, torch.ones(m, dtype=torch.float64).reshape(-1, 1).cuda()], \n",
    "                                                        dim = 1), p = 2, dim = 1)\n",
    "        elif self.encoding == 'stereo':\n",
    "            # X_prime = (1 / (X_sq_sum + 1)).reshape(-1, 1) \\\n",
    "                      # *(np.concatenate((2*X, (X_sq_sum - 1).reshape(-1, 1)), axis = 1))\n",
    "            X_prime = (1 / (X_sq_sum + 1)).reshape(-1, 1)*(torch.cat((2*X, (X_sq_sum - 1).reshape(-1, 1)), dim = 1))\n",
    "        else:\n",
    "            raise ValueError('encoding should be \"amplit\" or \"stereo\"')\n",
    "                        \n",
    "        # Function to calculate terms in the Quantum Centroids and quantum Helstrom \n",
    "        # observable for each class\n",
    "        def centroid_terms_func(i):\n",
    "            # Determine rows (samples) in X' belonging to either class\n",
    "            X_prime_class = X_prime[y_class_index == i]\n",
    "            \n",
    "            # Number of rows (samples) in X' belonging to either class\n",
    "            m_class = X_prime_class.shape[0]\n",
    "            \n",
    "            # Split X' belonging to either class into n_splits subsets, row-wise\n",
    "            # X_prime_class_split = np.array_split(X_prime_class, \n",
    "                                                 # indices_or_sections = self.n_splits, \n",
    "                                                 # axis = 0)\n",
    "            X_prime_class_split = torch.chunk(X_prime_class, \n",
    "                                              chunks = self.n_splits,\n",
    "                                              dim = 0)\n",
    "            \n",
    "            # Function to calculate sum of quantum densities belonging to each class, \n",
    "            # per subset split\n",
    "            def X_prime_class_split_func(j):\n",
    "                # Counter for j-th split of X'\n",
    "                X_prime_class_split_jth = X_prime_class_split[j]\n",
    "                \n",
    "                # Number of rows (samples) in j-th split of X'\n",
    "                m_class_split = X_prime_class_split_jth.shape[0]\n",
    "            \n",
    "                # Number of rows/columns in density matrix\n",
    "                density_nrow_ncol = (n + 1)**self.n_copies\n",
    "            \n",
    "                # Initialize arrays density_sum, centroid and q_hels_obs_terms\n",
    "                # density_sum = np.zeros((density_nrow_ncol, density_nrow_ncol))\n",
    "                density_sum = torch.zeros([density_nrow_ncol, density_nrow_ncol], dtype = torch.float64).cuda()\n",
    "                centroid = density_sum              \n",
    "                q_hels_obs_terms = density_sum\n",
    "                for k in range(m_class_split):\n",
    "                    # Encode vectors into quantum densities\n",
    "                    X_prime_class_split_each_row = X_prime_class_split_jth[k, :]\n",
    "                    # density_each_row = np.dot(X_prime_class_split_each_row.reshape(-1, 1),\n",
    "                                              # X_prime_class_split_each_row.reshape(1, -1))\n",
    "                    density_each_row = torch.matmul(X_prime_class_split_each_row.reshape(-1, 1),\n",
    "                                                    X_prime_class_split_each_row.reshape(1, -1))\n",
    "                \n",
    "                    # Calculate n-fold Kronecker tensor product\n",
    "                    if self.n_copies == 1:\n",
    "                        density_each_row = density_each_row\n",
    "                    else:\n",
    "                        density_each_row_copy = density_each_row\n",
    "                        for u in range(self.n_copies - 1):\n",
    "                            # density_each_row = np.kron(density_each_row, density_each_row_copy)\n",
    "                            density_each_row = kronecker(density_each_row, density_each_row_copy)\n",
    "                \n",
    "                    # Calculate sum of quantum densities belonging to either class, per subset split\n",
    "                    density_sum = density_sum + density_each_row\n",
    "                return density_sum\n",
    "            \n",
    "            # Function to calculate centroid belonging to either class\n",
    "            def centroid():\n",
    "                # Calculate sum of quantum densities belonging to either class\n",
    "                # density_sum_class = np.sum(Parallel(n_jobs = self.n_jobs) \\\n",
    "                                          # (delayed(X_prime_class_split_func)(j) for j in range(self.n_splits)), axis = 0)\n",
    "                if __name__ == '__main__':\n",
    "                    with Pool(processes = self.n_jobs) as p1:\n",
    "                        density_sum_list = p1.map(X_prime_class_split_func, range(self.n_splits))\n",
    "                        density_sum_class = torch.stack(density_sum_list, dim = 0).sum(dim = 0)\n",
    "                \n",
    "                # Calculate Quantum Centroid belonging to either class\n",
    "                # Added ZeroDivisionError as required by sklearn check_estimator\n",
    "                try:\n",
    "                    centroid = (1 / m_class)*density_sum_class\n",
    "                except ZeroDivisionError:\n",
    "                    centroid = 0   #**************\n",
    "                return centroid\n",
    "            \n",
    "            # Calculate centroid belonging to either class\n",
    "            centroid_class = centroid()\n",
    "                            \n",
    "            # Calculate terms in the quantum Helstrom observable belonging to either class\n",
    "            if self.class_wgt == 'equi':\n",
    "                q_hels_obs_terms = 0.5*centroid_class\n",
    "            elif self.class_wgt == 'weighted':\n",
    "                q_hels_obs_terms = (m_class / m)*centroid_class\n",
    "            else:\n",
    "                raise ValueError('class_wgt should be \"equi\" or \"weighted\"')\n",
    "            return m_class, centroid_class, q_hels_obs_terms\n",
    "                            \n",
    "        # Calculate Quantum Centroids and terms in the quantum Helstrom observable belonging to either class\n",
    "        # centroid_terms = np.array(Parallel(n_jobs = self.n_jobs) \\\n",
    "                                          # (delayed(centroid_terms_func)(i) for i in range(2)))\n",
    "        if __name__ == '__main__':\n",
    "            with Pool(processes = self.n_jobs) as p2:\n",
    "                centroid_terms = p2.map(centroid_terms_func, range(2))\n",
    "              \n",
    "        # Determine Quantum Centroids\n",
    "        self.centroid_ = centroid_terms[:, 1]\n",
    "           \n",
    "        # Calculate quantum Helstrom observable\n",
    "        self.q_hels_obs_ = centroid_terms[0, 2] - centroid_terms[1, 2]     \n",
    "        \n",
    "        # Calculate eigenvalues w and eigenvectors v of the quantum Helstrom observable\n",
    "        # w, v = np.linalg.eigh(self.q_hels_obs_)\n",
    "        w, v = torch.eig(self.q_hels_obs_, eigenvectors = True)\n",
    "        \n",
    "        # Length of w\n",
    "        # len_w = len(w)\n",
    "        len_w = len(w[:, 0])\n",
    "        \n",
    "        # Initialize array eigval_class\n",
    "        # eigval_class = np.empty_like(w)\n",
    "        eigval_class = torch.empty_like(w[:, 0], dtype = torch.float64).cuda()\n",
    "        for i in range(len_w):\n",
    "            # Create an array of 0s and 1s to indicate positive and negative eigenvalues\n",
    "            # respectively\n",
    "            # if w[i] > 0:\n",
    "            if w[:, 0][i] > 0:\n",
    "                eigval_class[i] = 0\n",
    "            else:\n",
    "                eigval_class[i] = 1\n",
    "        \n",
    "        # Transpose matrix v containing eigenvectors to row-wise\n",
    "        eigvec = v.T\n",
    "        \n",
    "        # Function to calculate sum of the projectors corresponding to positive and negative\n",
    "        # eigenvalues respectively\n",
    "        def sum_proj_func(i):\n",
    "            # Split eigenvectors belonging to positive or negative eigenvalues into n_splits subsets\n",
    "            # eigvec_class_split = np.array_split(eigvec[eigval_class == i], \n",
    "                                                # indices_or_sections = self.n_splits, \n",
    "                                                # axis = 0)\n",
    "            eigvec_class_split = torch.chunk(eigvec[eigval_class == i], \n",
    "                                             chunks = self.n_splits, \n",
    "                                             dim = 0)\n",
    "            \n",
    "            # Function to calculate sum of the projectors corresponding to positive and negative\n",
    "            # eigenvalues respectively, per subset split\n",
    "            def eigvec_class_split_func(j):\n",
    "                # Initialize array proj_sum_split\n",
    "                proj_sum_split = torch.zeros_like(self.q_hels_obs_, dtype = torch.float64).cuda()\n",
    "                for k in eigvec_class_split[j]:\n",
    "                    # Calculate sum of the projectors corresponding to positive and negative\n",
    "                    # eigenvalues respectively, per subset split\n",
    "                    # proj_sum_split = proj_sum_split + np.dot(k.reshape(-1, 1), k.reshape(1, -1))\n",
    "                    proj_sum_split = proj_sum_split + torch.matmul(k.reshape(-1, 1), k.reshape(1, -1))\n",
    "                return proj_sum_split        \n",
    "            # return np.sum(Parallel(n_jobs = self.n_jobs) \\\n",
    "                         # (delayed(eigvec_class_split_func)(j) for j in range(self.n_splits)), axis = 0)\n",
    "            if __name__ == '__main__':\n",
    "                with Pool(processes = self.n_jobs) as p3:\n",
    "                    proj_sum_split_list = p3.map(eigvec_class_split_func, range(self.n_splits))\n",
    "            return torch.stack(proj_sum_split_list, dim = 0).sum(dim = 0)\n",
    "        \n",
    "        # Calculate sum of the projectors corresponding to positive and negative eigenvalues\n",
    "        # respectively\n",
    "        # self.proj_sum_ = Parallel(n_jobs = self.n_jobs) \\\n",
    "                         # (delayed(sum_proj_func)(i) for i in range(2))\n",
    "        if __name__ == '__main__':\n",
    "            with Pool(processes = self.n_jobs) as p4:\n",
    "                self.proj_sum_ = p4.map(sum_proj_func, range(2))\n",
    "                       \n",
    "        # Calculate Helstrom bound\n",
    "        # self.hels_bound_ = (centroid_terms[0, 0] / m)*np.einsum('ij,ji->', self.centroid_[0], \n",
    "                                                                # self.proj_sum_[0]) \\\n",
    "                           # + (centroid_terms[1, 0] / m)*np.einsum('ij,ji->', self.centroid_[1], \n",
    "                                                                  # self.proj_sum_[1])\n",
    "        self.hels_bound_ = (centroid_terms[0, 0] / m)*torch.einsum('ij,ji->', self.centroid_[0], \n",
    "                                                                   self.proj_sum_[0]).item() \\\n",
    "                           + (centroid_terms[1, 0] / m)*torch.einsum('ij,ji->', self.centroid_[1], \n",
    "                                                                     self.proj_sum_[1]).item()\n",
    "        return self\n",
    "        \n",
    "    \n",
    "    # Function for predict_proba\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Performs HQC classification on X and returns the trace of the dot product of the densities \n",
    "        and the sum of the projectors with corresponding positive and negative eigenvalues respectively.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The input samples. An array of int or float.       \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        trace_matrix : array-like, shape (n_samples, 2)\n",
    "            Column index 0 corresponds to the trace of the dot product of the densities and the sum  \n",
    "            of projectors with positive eigenvalues. Column index 1 corresponds to the trace of the  \n",
    "            dot product of the densities and the sum of projectors with negative eigenvalues. An array \n",
    "            of float.\n",
    "        \"\"\"\n",
    "        # Send tensor self.proj_sum_ from GPU to CPU and cast into an array\n",
    "        self.proj_sum_arr_ = self.proj_sum_.cpu().numpy()\n",
    "                \n",
    "        # Check if fit had been called\n",
    "        # check_is_fitted(self, ['proj_sum_'])\n",
    "        check_is_fitted(self, ['proj_sum_arr_'])\n",
    "\n",
    "        # Cast tensor X into an array\n",
    "        X_arr = X.numpy()        \n",
    "        \n",
    "        # Input validation\n",
    "        # X = check_array(X)\n",
    "        X = check_array(X_arr)\n",
    "        \n",
    "        # Send tensor X from CPU to GPU\n",
    "        X = X.cuda()     \n",
    "        \n",
    "        # Cast X to float to ensure all following calculations below are done in float \n",
    "        # rather than integer\n",
    "        # X = X.astype(float)  \n",
    "        X = torch.DoubleTensor(X)\n",
    "        \n",
    "        # Rescale X\n",
    "        X = self.rescale*X        \n",
    "        \n",
    "        # Calculate sum of squares of each row (sample) in X\n",
    "        # X_sq_sum = (X**2).sum(axis = 1)\n",
    "        X_sq_sum = (X**2).sum(dim = 1)\n",
    "        \n",
    "        # Number of rows in X\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Number of columns in X\n",
    "        n = X.shape[1]\n",
    "\n",
    "        # Calculate X' using amplitude or inverse of the standard stereographic projection \n",
    "        # encoding method\n",
    "        if self.encoding == 'amplit':\n",
    "            # X_prime = normalize(np.concatenate((X, np.ones(m).reshape(-1, 1)), axis = 1))\n",
    "            X_prime = nn.functional.normalize(torch.cat([X, torch.ones(m, dtype=torch.float64).reshape(-1, 1).cuda()],\n",
    "                                                        dim = 1), p = 2, dim = 1)\n",
    "        elif self.encoding == 'stereo':\n",
    "            # X_prime = (1 / (X_sq_sum + 1)).reshape(-1, 1) \\\n",
    "                      # *(np.concatenate((2*X, (X_sq_sum - 1).reshape(-1, 1)), axis = 1))\n",
    "            X_prime = (1 / (X_sq_sum + 1)).reshape(-1, 1)*(torch.cat((2*X, (X_sq_sum - 1).reshape(-1, 1)), dim = 1))\n",
    "        else:\n",
    "            raise ValueError('encoding should be \"amplit\" or \"stereo\"')\n",
    "                       \n",
    "        # Function to calculate trace values for each class\n",
    "        def trace_func(i):\n",
    "            # Split X' into n_splits subsets, row-wise\n",
    "            # X_prime_split = np.array_split(X_prime, \n",
    "                                           # indices_or_sections = self.n_splits, \n",
    "                                           # axis = 0)\n",
    "            X_prime_split = torch.chunk(X_prime,\n",
    "                                        chunks = self.n_splits,\n",
    "                                        dim = 0)\n",
    "            \n",
    "            # Function to calculate trace values for each class, per subset split\n",
    "            def trace_split_func(j):\n",
    "                # Counter for j-th split X'\n",
    "                X_prime_split_jth = X_prime_split[j]\n",
    "                \n",
    "                # Number of rows (samples) in j-th split X'\n",
    "                X_prime_split_m = X_prime_split_jth.shape[0]\n",
    "                \n",
    "                # Initialize array trace_class_split\n",
    "                # trace_class_split = np.empty(X_prime_split_m)\n",
    "                trace_class_split = torch.empty(X_prime_split_m, dtype = torch.float64).cuda()\n",
    "                for k in range(X_prime_split_m):\n",
    "                    # Encode vectors into quantum densities\n",
    "                    X_prime_split_each_row = X_prime_split_jth[k, :]\n",
    "                    # density_each_row = np.dot(X_prime_split_each_row.reshape(-1, 1), \n",
    "                                              # X_prime_split_each_row.reshape(1, -1))\n",
    "                    density_each_row = torch.matmul(X_prime_split_each_row.reshape(-1, 1),\n",
    "                                                    X_prime_split_each_row.reshape(1, -1))\n",
    "                                                                  \n",
    "                    # Calculate n-fold Kronecker tensor product\n",
    "                    if self.n_copies == 1:     \n",
    "                        density_each_row = density_each_row\n",
    "                    else:\n",
    "                        density_each_row_copy = density_each_row\n",
    "                        for u in range(self.n_copies - 1):\n",
    "                            # density_each_row = np.kron(density_each_row, density_each_row_copy)\n",
    "                            density_each_row = kronecker(density_each_row, density_each_row_copy)\n",
    "                        \n",
    "                    # Calculate trace of the dot product of density of each row and sum of projectors \n",
    "                    # with corresponding positive and negative eigenvalues respectively    \n",
    "                    # trace_class_split[k] = np.einsum('ij,ji->', density_each_row, self.proj_sum_[i])\n",
    "                    trace_class_split[k] = torch.einsum('ij,ji->', density_each_row, self.proj_sum_[i]).item()\n",
    "                return trace_class_split\n",
    "            \n",
    "            # Calculate trace values for each class, per subset split\n",
    "            # trace_class = Parallel(n_jobs = self.n_jobs) \\\n",
    "                          # (delayed(trace_split_func)(j) for j in range(self.n_splits))\n",
    "            if __name__ == '__main__':\n",
    "                with Pool(processes = self.n_jobs) as p5:\n",
    "                    trace_class = p5.map(trace_split_func, range(self.n_splits))\n",
    "            # return np.concatenate(trace_class, axis = 0)\n",
    "            return torch.cat(trace_class, dim = 0)\n",
    "            \n",
    "        # Calculate trace values for each class\n",
    "        # trace_matrix = np.transpose(Parallel(n_jobs = self.n_jobs) \\\n",
    "                                   # (delayed(trace_func)(i) for i in range(2)))\n",
    "        if __name__ == '__main__':\n",
    "            with Pool(processes = self.n_jobs) as p6:\n",
    "                trace_matrix = torch.stack(p6.map(trace_func, range(2)), dim = 1)\n",
    "        return trace_matrix\n",
    "        \n",
    "    \n",
    "    # Function for predict\n",
    "    def predict(self, X):\n",
    "        \"\"\"Performs HQC classification on X and returns the binary classes.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The input samples. An array of int or float.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self.classes_[predict_trace_index] : array-like, shape (n_samples,)\n",
    "            The predicted binary classes. An array of str, int or float.\n",
    "        \"\"\"\n",
    "        # Determine column index with the higher trace value in trace_matrix\n",
    "        # If both columns have the same trace value, returns column index 0\n",
    "        # predict_trace_index = np.argmax(self.predict_proba(X), axis = 1)\n",
    "        predict_trace_index = torch.argmax(self.predict_proba(X), axis = 1)\n",
    "        # Returns the predicted binary classes\n",
    "        return self.classes_[predict_trace_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import torch\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_classification(n_samples=2000, n_features=20, n_classes=2, random_state=0)\n",
    "\n",
    "# Cast X and y numpy arrays into Pytorch tensors as the HQC estimator accepts Pytorch tensors (stored in CPU)\n",
    "X_tsr = torch.DoubleTensor(X)   # Tensor with floating point elements\n",
    "y_tsr = torch.LongTensor(y)   # Tensor with integer elements\n",
    "\n",
    "# Fit and predict model\n",
    "model = HQC(rescale=0.5, n_copies=4, n_jobs=1, n_splits=2).fit(X_tsr, y_tsr)\n",
    "y_hat_tsr = model.predict(X_tsr)\n",
    "\n",
    "# Send tensor y_hat_tsr from GPU to CPU, and cast to numpy array\n",
    "y_hat = y_hat_tsr.cpu().numpy()\n",
    "\n",
    "# Check F1 score and Helstrom bound values\n",
    "from sklearn import metrics\n",
    "print(metrics.f1_score(y, y_hat))\n",
    "print(model.Hels_bound_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
